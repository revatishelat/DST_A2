{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/revatishelat/DST_A2/blob/main/report/06_Conclusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Techniques"
      ],
      "metadata": {
        "id": "4t9NoAeoPyO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we tried a variety of text processing techniques. In general, the earlier methods like Bag of Words and Word2Vec, which provide straightforward embeddings of each token, were more computationally efficient and ran faster, despite not having a contextual awareness of each token. The more recent machine learning methods, such as BERT and RNNs, are a lot more computationally complex. Because of this, we were only able to run smaller toy models or load the models pre-trained. Thus, their performance on this task was generally lower than the simpler methods, but we can imagine that with sufficient computational resources and time, we could train these models fully on our task and achieve very good accuracy scores, as suggested by their state-of-the-art performance in the literature."
      ],
      "metadata": {
        "id": "K9X-EId1P5Aw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag of Words\n",
        "\n",
        "Once tuned, with the general class removed, both embedders produce good performance with good efficiency considering the dataset is large and messy. Interestingly the simpler embedder, count vectorizer, results in better performance, this could be due to very specific medical terms occuring in a document but not throughout the class it belongs to. The inverse-document-frequency factor would then weight these highly and create noise in the data if the terms are not found across the whole class. Overall, the limiting factor in the models efficiency was the preprocessing, this step can be easily parallelised, by preprocessing multiple documents from the corpus at once, therefore these models are scaleable to larger datasets."
      ],
      "metadata": {
        "id": "XrSQ6FAPP7KR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec\n",
        "\n",
        "For the exploration of Word2Vec embeddings with a convolutional neural network classification our methodology included:\n",
        "* Training our own word2vec model on the provided medical abstract data\n",
        "* Architecture and parameter exploration derived from previous works\n",
        "* Accuracy analysis using confusion matrices for predictions\n",
        "* Exploration of misclassification for the general pathological diseases class through t-SNE plots of word embeddings\n",
        "* Analysis of classification for the model without the general class for further conclusions about the capabilities of our Word2Vec and CNN models at text classification for pre-labelled medical abstracts.  \n",
        "\n",
        "From this research valuable insights were found with the visualisation of the Word2Vec embeddings for each class with t-SNE plots, as a clear larger spread of the data from embeddings was found for class 5, thus supporting any inaccuracies for classification where the general pathological conditions class is considered. Alongside, a significant improvement for classification accuracy from ~50% to ~75% with the removal of the general medical abstract class. This shows that while the methodology employed struggled with identifying patterns for the text corpus with the general class included (where spread and overlap seem to be the route of the problem), the model could identify significant and distinct patterns within the other four more specific abstract cases. Although 75% is not the highest accuracy score derived from our exploration, with sufficient GPU power and time, a more in depth approach at analysing the CNN structure and hyperparameter for fine-tuning would suggest a more accurate model that could compete, if not improve on other methods, as deep learning implementation with a strong word embedding model (like Word2Vec) that explores relationships in meaning, grammar and context would provide a powerful classification tool."
      ],
      "metadata": {
        "id": "BgCOgJesP-F3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT\n",
        "\n",
        "The performance of BERT was not amazing, achieving at best around 50% accuracy with a classification head. The omission of this class 2 (digestive system diseases) in its predictions is a big failure, and could be catastrophic if using this model in a clinical setting for assisting doctors, as it might lead to an incorrect diagnosis. However, the performance was better than the 'dummy' classifier, suggesting BERT is capturing useful information in embedding the medical abstracts.\n",
        "\n",
        "There are several reasons why BERT did not work as well as expected.\n",
        "\n",
        "Firstly, many of the methods had a maximum input sequence, meaning we had to truncate the medical abstracts, potentially losing valuable information. In reality, a 'sliding window' inference should be employed by embedding each abstract in chunks and pooling these embeddings together, to ensure every word is captured in the embedding.\n",
        "\n",
        "Secondly, the training of the BERT models may have been unsuitable for our task. The DistilBERT was not trained on specific medical data so its vocabulary may not contain many of the words found in the medical abstracts, resulting to poor embeddings. The downstream tasks (such as predicting masked words) that all the BERTs were trained on may be unsuitable too. These downstream tasks may have led to a general understading of (medical) text data, but these models may not be advanced enough to distinguish between specialised medical topics to separate our dataset into its classes. More sophisticated methods, trained on much larger data, may be needed here.\n",
        "\n",
        "Thirdly, as we have seen in other methods, the data imbalance also contributed to decreased performance. In BERT's case, the training of the classification head was dominated by the larger classes, causing it to fail at classifying or predicting the smaller classes.\n",
        "\n",
        "To improve BERT's performance on this task, we could consider invoking methods that actually continue the training of the BERT models, updating their parameters. We could either train our own BERT model entirely from scratch, using the classification of medical abstracts as our downstream tasks; however, this would require a huge amount of computation and data and may be unrealistic. The other option would be to fine-tune a pre-trained BERT model in the training loop, where the BERT model parameters are updated as well as the classification head's. This would still require a much larger amount of computation than was available to us in this project, but would not necessarily need the volume of data to train a BERT model from scratch. In either case, employing these methods would push BERT to learn an even more useful latent representation for each medical abstract, improving its classfication ability."
      ],
      "metadata": {
        "id": "QzeET26ZQBdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN"
      ],
      "metadata": {
        "id": "eTqegila49N1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "17lfIxlPQFdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main issue with the data was class 5, the 'general pathological conditions' class. Since this class covers a broader range of topics than the others, abstracts within this class will be less correlated than abstracts belonging to a more specific class, making classification much more difficult. Furthermore, this class dominates the dataset, and so the models we investigated were often unable to perform well. Much more robust and computationally intensive techniques would be required to gain improved results. When we removed this class in some of our analyses, we were left with a much more manageable task and our models were able to find clearer patterns in the dataset and produce better results."
      ],
      "metadata": {
        "id": "CN_L-WDnQMGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation"
      ],
      "metadata": {
        "id": "8rEVnDQFQWYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Where models require a large amount of RAM or computation power, which could be due to many computations or storing many outputs, computers running on standard CPUs lack the power of parallelism, that GPUs (graphic processing units) are built for. Thus, when running BERT implementations or training large and complicated convolutional neural networks, the use of parallelism from a good GPU is suffiently justified, since it enabled computations to be divided, stored and run on multiple separate processors simultaneously, speeding up computaitons ten-fold. Thus our implementations with the public Google Colab for the large corpus of abstracts text used in our research provides suffient and necessary speedup in some cases."
      ],
      "metadata": {
        "id": "K_0bt_-WQc1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Impact and future directions"
      ],
      "metadata": {
        "id": "sFQ3ysW6QjnL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In summary, we investigated several techniques for natural language processing and developed our understanding of how they operate on data at scale.\n",
        "\n",
        "Developing models that can classify medical text is significant, since it represents progress towards a broader goal of increasing computational understanding of medical natural language. This has huge implications on the creation of future technologies in the medical realm, such as AI assistants that help clinicians to get information fast and make critical decisions.\n",
        "\n",
        "Given more time or resources, we would investigate: fine-tuning deep learning models like BERT rather than only using them as pre-trained models; further methods, such as dimensionality reduction, to understand high-dimensional embeddings; further methods to tackle class imbalance; and finally how to combine multiple techniques that we investigated to build a more robust model."
      ],
      "metadata": {
        "id": "NM5kTs2JQ1EK"
      }
    }
  ]
}
