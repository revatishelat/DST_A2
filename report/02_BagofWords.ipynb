{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Wv8NfwgMj-6T",
        "id5U2syr8X5X",
        "RcXw1dx08mg4",
        "PcFpj4kP_WtK",
        "tcBKyxa5vmEo",
        "Am6kHZoNvhur",
        "kmMjQxr-bTig",
        "H24lF2mdvrSE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We will implement the bag of words model using 2 methods of text embeddding and a naive bayes classifier, attempt to tune them to obtain the best performance, and compare said performance."
      ],
      "metadata": {
        "id": "BYAFHIa178FY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## imports/functions/reading in data"
      ],
      "metadata": {
        "id": "Wv8NfwgMj-6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split , GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "en_stop = set(nltk.corpus.stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkJE1V0f70h3",
        "outputId": "f1c45b37-1699-4157-cf0a-ad7525a3bffd"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(doc):\n",
        "        #lowercases document\n",
        "        doc = doc.lower()\n",
        "        #removes any non-letter characters\n",
        "        #tokenize\n",
        "        toks = nltk.word_tokenize(doc)\n",
        "        #remove tokens of lenth <= n (can be varied)\n",
        "        toks = [tok for tok in toks if len(tok) > 1]\n",
        "        #remove tokens that dont exclusively contain letters\n",
        "        toks = [tok for tok in toks if re.match('^[a-zA-Z]+$', tok)]\n",
        "        #remove stopwords\n",
        "        toks = [tok for tok in toks if tok not in en_stop]\n",
        "        #lemmatize\n",
        "        toks = [WordNetLemmatizer().lemmatize(tok) for tok in toks]\n",
        "        return toks\n",
        "\n",
        "def preprocess4(doc):\n",
        "        #lowercases document\n",
        "        doc = doc.lower()\n",
        "        #removes any non-letter characters\n",
        "        #tokenize\n",
        "        toks = nltk.word_tokenize(doc)\n",
        "        #remove tokens of lenth <= n (can be varied)\n",
        "        toks = [tok for tok in toks if len(tok) > 4]\n",
        "        #remove tokens that dont exclusively contain letters\n",
        "        toks = [tok for tok in toks if re.match('^[a-zA-Z]+$', tok)]\n",
        "        #remove stopwords\n",
        "        toks = [tok for tok in toks if tok not in en_stop]\n",
        "        #lemmatize\n",
        "        toks = [WordNetLemmatizer().lemmatize(tok) for tok in toks]\n",
        "        return toks\n",
        "def dummy_tok(doc):\n",
        "  return doc\n",
        "def performance(conf_mat):\n",
        "  TP = 0\n",
        "  for i in range(conf_mat.shape[0]):\n",
        "    Class = df_labels['condition_name'][i]\n",
        "    tp = conf_mat[i, i]\n",
        "    fp = np.sum(conf_mat[:, i]) - tp\n",
        "    fn = np.sum(conf_mat[i, :]) - tp\n",
        "    tn = np.sum(conf_mat) - (tp + fp + fn)\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "    TP += tp\n",
        "    print(Class.upper())\n",
        "    print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
        "  accuracy_tot = TP / np.sum(conf_mat)\n",
        "  print(f\"Total Accuracy: {accuracy_tot:.3f}\")\n",
        "  return"
      ],
      "metadata": {
        "id": "7MkT14aEvLv1"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('medical_tc_train.csv')\n",
        "df_test = pd.read_csv('medical_tc_test.csv')\n",
        "df_labels = pd.read_csv('medical_tc_labels.csv')"
      ],
      "metadata": {
        "id": "4HZPIJd4vPtc"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRuJOmrs7cJ4",
        "outputId": "d50806ca-5ee0-4e44-8b0c-729329829e03"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11550, 2)\n",
            "(2888, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CountVectorizer"
      ],
      "metadata": {
        "id": "id5U2syr8X5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corp_train = df_train['medical_abstract']\n",
        "corp_test = df_test['medical_abstract']"
      ],
      "metadata": {
        "id": "IhCV4EEa5ACf"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We begin with a basic embedder, count vectorizer. Creates a dictionary of all words in the training corpus and returns a word frequency vector for each document."
      ],
      "metadata": {
        "id": "aQCVkje-MuR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = CountVectorizer(preprocessor=preprocess, tokenizer=dummy_tok)\n",
        "\n",
        "count_mat_train = count.fit_transform(corp_train)\n",
        "print(count_mat_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjt53VMj6Kta",
        "outputId": "b0189176-b380-418e-910e-46ffa5acb136"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11550, 28079)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then transform the train data using the dictionary created before."
      ],
      "metadata": {
        "id": "SJdYvvu8NUqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_mat_test = count.transform(corp_test)\n",
        "print(count_mat_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtHxDxbi7MJH",
        "outputId": "bf8931bd-8364-4aa7-f758-be686ad152f6"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2888, 28079)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_train = df_train['condition_label']\n",
        "labels_test = df_test['condition_label']"
      ],
      "metadata": {
        "id": "YKBxjovf7l7J"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use a multinomial naive bayes classifier as it can handle our large dataset efficiently."
      ],
      "metadata": {
        "id": "fTmGiOdVNqSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MultinomialNB()"
      ],
      "metadata": {
        "id": "X7MbhOWWwR4N"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the classifier using the embedded training data."
      ],
      "metadata": {
        "id": "bCg-wJF3N_lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit(count_mat_train, labels_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "-dGbedVf0fCP",
        "outputId": "f9866169-9676-4c4b-d2ed-4a56c2706c13"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We make predictions on the embedded test data and compare with test data labels."
      ],
      "metadata": {
        "id": "WGV4nYGXOGRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_pred = classifier.predict(count_mat_test)"
      ],
      "metadata": {
        "id": "vtVEMF6x8g_a"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat = confusion_matrix(labels_test, labels_pred)\n",
        "print(conf_mat)"
      ],
      "metadata": {
        "id": "_yXBQBHS8hL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee4b2de9-aac7-4a3a-a977-627d7218a63b"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[490  40  35  14  54]\n",
            " [ 37 188   6  10  58]\n",
            " [ 28   8 240  32  77]\n",
            " [ 10  12  33 466  89]\n",
            " [171 141 131 207 311]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance(conf_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7ytu8hs7GQo",
        "outputId": "749fe9da-587b-4b3e-d6a4-076843b82d4f"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEOPLASMS\n",
            "Accuracy: 0.87, Precision: 0.67, Recall: 0.77\n",
            "DIGESTIVE SYSTEM DISEASES\n",
            "Accuracy: 0.89, Precision: 0.48, Recall: 0.63\n",
            "NERVOUS SYSTEM DISEASES\n",
            "Accuracy: 0.88, Precision: 0.54, Recall: 0.62\n",
            "CARDIOVASCULAR DISEASES\n",
            "Accuracy: 0.86, Precision: 0.64, Recall: 0.76\n",
            "GENERAL PATHOLOGICAL CONDITIONS\n",
            "Accuracy: 0.68, Precision: 0.53, Recall: 0.32\n",
            "Total Accuracy: 0.587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems to have good predictions for classes 1-4, but class 5 is causing problems."
      ],
      "metadata": {
        "id": "FFXtXg3A9btX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65fl0XO4AdhM",
        "outputId": "3425dd70-dfbf-4c35-aae6-eb5ccb66e862"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   condition_label                   condition_name\n",
            "0                1                        neoplasms\n",
            "1                2        digestive system diseases\n",
            "2                3          nervous system diseases\n",
            "3                4          cardiovascular diseases\n",
            "4                5  general pathological conditions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is to be expected since abstracts belonging to 'general pathological conditions' will be less correlated than abstracts belonging to a more specific class."
      ],
      "metadata": {
        "id": "IOyIQv9HQVbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = df_train['condition_label'].value_counts()\n",
        "print(class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDpJrjKtPhHA",
        "outputId": "4128b594-3290-4632-8be6-62dfe8c85eb9"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5    3844\n",
            "1    2530\n",
            "4    2441\n",
            "3    1540\n",
            "2    1195\n",
            "Name: condition_label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The general class is also the dominant class, therefore our overall accuracy will be quite poor."
      ],
      "metadata": {
        "id": "mU275Mbv243c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CountVectorizer, short words removed"
      ],
      "metadata": {
        "id": "RcXw1dx08mg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We might expect that in the medical context, short words contain less information than longer ones. Therefore we will experiment with removing tokens of length 4 or less to improve performance."
      ],
      "metadata": {
        "id": "fMKlUgHIuL02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count1 = CountVectorizer(preprocessor=preprocess4, tokenizer=tok)\n",
        "\n",
        "count_mat_train1 = count1.fit_transform(corp_train)\n",
        "print(count_mat_train1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhtrr_L32AlM",
        "outputId": "992e87c8-bc3b-48df-ec4c-afe8741200c0"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11550, 24875)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_mat_test1 = count1.transform(corp_test)\n",
        "print(count_mat_test1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCCCpW4_kl__",
        "outputId": "76cfa8b9-9873-42b4-b817-bebc0059b886"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2888, 24875)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier1 = MultinomialNB()"
      ],
      "metadata": {
        "id": "tmlIIdHPkmCW"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier1.fit(count_mat_train1, labels_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "O0dYYdB5kmEe",
        "outputId": "43f68e64-45da-491e-f600-e5a98f9b1a8d"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_pred1 = classifier1.predict(count_mat_test1)"
      ],
      "metadata": {
        "id": "GI28z0zOkmI_"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat1 = confusion_matrix(labels_test, labels_pred1)\n",
        "print(conf_mat1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_5hf8yHkmLP",
        "outputId": "13842dde-3560-40a8-855d-b9be6a5ee5fb"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[501  36  32  14  50]\n",
            " [ 37 187   5   7  63]\n",
            " [ 30  11 240  33  71]\n",
            " [ 14  12  32 461  91]\n",
            " [168 148 131 207 307]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance(conf_mat1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ2vX-M1kmO2",
        "outputId": "bb3ce2ac-57ad-499c-c457-6c263ad85871"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEOPLASMS\n",
            "Accuracy: 0.87, Precision: 0.67, Recall: 0.79\n",
            "DIGESTIVE SYSTEM DISEASES\n",
            "Accuracy: 0.89, Precision: 0.47, Recall: 0.63\n",
            "NERVOUS SYSTEM DISEASES\n",
            "Accuracy: 0.88, Precision: 0.55, Recall: 0.62\n",
            "CARDIOVASCULAR DISEASES\n",
            "Accuracy: 0.86, Precision: 0.64, Recall: 0.76\n",
            "GENERAL PATHOLOGICAL CONDITIONS\n",
            "Accuracy: 0.68, Precision: 0.53, Recall: 0.32\n",
            "Total Accuracy: 0.587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see no change in performance, but a slight improvement in efficiency. So we will proceed using this preprocesser."
      ],
      "metadata": {
        "id": "9lPKicA5qy8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tf-Idf"
      ],
      "metadata": {
        "id": "PcFpj4kP_WtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will use tf-idf embedding, this method uses word frequency as before but also takes into account the rarity of a word across the corpus. This may lead to more information being captured and an improved performance for the classifier."
      ],
      "metadata": {
        "id": "m3zDA3-cWA7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(preprocessor=preprocess4, tokenizer=tok)\n",
        "tfidf_mat_train = tfidf.fit_transform(corp_train)"
      ],
      "metadata": {
        "id": "kFH63y37Cb8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08dd4778-7d0b-4698-bae2-acc39fb380a4"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_mat_test = tfidf.transform(corp_test)\n",
        "print(tfidf_mat_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OhD8_tlsTgO",
        "outputId": "cbf4284f-aa9c-4666-a3f7-4a39c56910a3"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2888, 24875)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier2 = MultinomialNB()"
      ],
      "metadata": {
        "id": "bi5AAa0E-7Qs"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier2.fit(tfidf_mat_train, labels_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "7jHPhan7--3t",
        "outputId": "10f8d882-e72a-4754-e667-eae30dc3f315"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_pred2 = classifier2.predict(tfidf_mat_test)"
      ],
      "metadata": {
        "id": "kT-3LSDz_EVs"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat2 = confusion_matrix(labels_test, labels_pred2)\n",
        "print(conf_mat2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ_UA1HS_S8X",
        "outputId": "e1c6043c-7ebf-4f5a-ea6f-5562a5ff9d01"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[434   0   0   9 190]\n",
            " [ 30   6   1   7 255]\n",
            " [ 21   0  12  24 328]\n",
            " [  6   0   2 364 238]\n",
            " [111   1   7 140 702]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance(conf_mat2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krreQzLHDDZP",
        "outputId": "88a47b2a-222d-4b74-f1ff-7b8e5f34a8d4"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEOPLASMS\n",
            "Accuracy: 0.87, Precision: 0.72, Recall: 0.69\n",
            "DIGESTIVE SYSTEM DISEASES\n",
            "Accuracy: 0.90, Precision: 0.86, Recall: 0.02\n",
            "NERVOUS SYSTEM DISEASES\n",
            "Accuracy: 0.87, Precision: 0.55, Recall: 0.03\n",
            "CARDIOVASCULAR DISEASES\n",
            "Accuracy: 0.85, Precision: 0.67, Recall: 0.60\n",
            "GENERAL PATHOLOGICAL CONDITIONS\n",
            "Accuracy: 0.56, Precision: 0.41, Recall: 0.73\n",
            "Total Accuracy: 0.526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classifier is heavily underpredicting classes 2 and 3, which we saw earlier are the least frequent in the dataset. We can attempt to fix this by setting a uniform prior on the classes, instead of the classifier learning the prior probabilities from the data."
      ],
      "metadata": {
        "id": "BKnGnRrpTcVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier3 = MultinomialNB(fit_prior=False)"
      ],
      "metadata": {
        "id": "QY-8Ycicvxbg"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier3.fit(tfidf_mat_train, labels_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "B6gqd6B8vxeC",
        "outputId": "fcdb6b30-2038-4466-c509-56746195b250"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(fit_prior=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(fit_prior=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(fit_prior=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_pred3 = classifier3.predict(tfidf_mat_test)"
      ],
      "metadata": {
        "id": "jT34ePe3vxgy"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat3 = confusion_matrix(labels_test, labels_pred3)\n",
        "print(conf_mat3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khGP3ZLYvxkG",
        "outputId": "53a00f0a-b2f5-4ee2-e084-f7d16b0006dd"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[486   9   7  14 117]\n",
            " [ 42  42   2  11 202]\n",
            " [ 30   1  87  37 230]\n",
            " [ 11   2   7 435 155]\n",
            " [144  26  42 185 564]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance(conf_mat3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZMtwYhqvxnJ",
        "outputId": "831f7d6f-54a7-49f3-fd13-873c4991f5b3"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEOPLASMS\n",
            "Accuracy: 0.87, Precision: 0.68, Recall: 0.77\n",
            "DIGESTIVE SYSTEM DISEASES\n",
            "Accuracy: 0.90, Precision: 0.53, Recall: 0.14\n",
            "NERVOUS SYSTEM DISEASES\n",
            "Accuracy: 0.88, Precision: 0.60, Recall: 0.23\n",
            "CARDIOVASCULAR DISEASES\n",
            "Accuracy: 0.85, Precision: 0.64, Recall: 0.71\n",
            "GENERAL PATHOLOGICAL CONDITIONS\n",
            "Accuracy: 0.62, Precision: 0.44, Recall: 0.59\n",
            "Total Accuracy: 0.559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " We can see a slight improvement, but the classifier is still underpredicting the underrepresented classes, this suggests overfitting. We can conduct a gridsearch to optimize the smoothing parameter alpha to prevent this."
      ],
      "metadata": {
        "id": "w6k4S_78gSyz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gridsearch"
      ],
      "metadata": {
        "id": "tcBKyxa5vmEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a pipeline containing the classifier."
      ],
      "metadata": {
        "id": "umuXfWkrYUPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('clf', MultinomialNB(fit_prior=False))])"
      ],
      "metadata": {
        "id": "bccNgHPJxFvw"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We check values of alpha between 0 and 3 in increments of .1"
      ],
      "metadata": {
        "id": "pfoIKjA0YgbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = np.arange(.1, 3, 0.1)\n",
        "param_grid = {\n",
        "    'clf__alpha': params}"
      ],
      "metadata": {
        "id": "LvZp9KFgxF0E"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')"
      ],
      "metadata": {
        "id": "5uaOW9kdxF3E"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We feed our training data to the grid search which returns the optimal value."
      ],
      "metadata": {
        "id": "YWakk43IZQcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(tfidf_mat_train, labels_train)\n",
        "print(grid_search.best_params_)"
      ],
      "metadata": {
        "id": "1iDIEdoExqFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9dc2f8d-6d19-490f-aafe-7bfebb1eb410"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'clf__alpha': 0.2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's see how this value of alpha affects our performance."
      ],
      "metadata": {
        "id": "i83sNdzWZZJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier4 = MultinomialNB(fit_prior=False, alpha=0.2)"
      ],
      "metadata": {
        "id": "4qNF_I7TU0HN"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier4.fit(tfidf_mat_train, labels_train)"
      ],
      "metadata": {
        "id": "Msr1TKW9U9cg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "222ae077-1bc3-47f6-fd66-9cea0d61f8c6"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.2, fit_prior=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.2, fit_prior=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.2, fit_prior=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_pred4 = classifier4.predict(tfidf_mat_test)"
      ],
      "metadata": {
        "id": "J0xgS9E_U9g7"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat4 = confusion_matrix(labels_test, labels_pred4)\n",
        "print(conf_mat4)"
      ],
      "metadata": {
        "id": "SAW1WFOQU9kg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8293724-90d4-4bc0-e735-427405397407"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[497  29  35  17  55]\n",
            " [ 39 166   5  11  78]\n",
            " [ 32  12 213  38  90]\n",
            " [ 13  10  22 484  81]\n",
            " [170 126 120 220 325]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance(conf_mat4)"
      ],
      "metadata": {
        "id": "lgr31QV9VFF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a56021-caf0-4d2a-b55d-8d67e9fa91e2"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEOPLASMS\n",
            "Accuracy: 0.86, Precision: 0.66, Recall: 0.79\n",
            "DIGESTIVE SYSTEM DISEASES\n",
            "Accuracy: 0.89, Precision: 0.48, Recall: 0.56\n",
            "NERVOUS SYSTEM DISEASES\n",
            "Accuracy: 0.88, Precision: 0.54, Recall: 0.55\n",
            "CARDIOVASCULAR DISEASES\n",
            "Accuracy: 0.86, Precision: 0.63, Recall: 0.79\n",
            "GENERAL PATHOLOGICAL CONDITIONS\n",
            "Accuracy: 0.67, Precision: 0.52, Recall: 0.34\n",
            "Total Accuracy: 0.583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see greatly improved results. Motivated by this, we also conduct a gridsearch to find the optimal smoothing parameter for the count vectorizer, also using the uniform prior to help with the unbalanced data."
      ],
      "metadata": {
        "id": "249M4g-fVNsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(count_mat_train1, labels_train)\n",
        "print(grid_search.best_params_)"
      ],
      "metadata": {
        "id": "mVxv_WmsV-rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5fe2416-6440-4592-e4b1-b1ae2f1bb71e"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'clf__alpha': 2.5000000000000004}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier5 = MultinomialNB(fit_prior=False, alpha=2.5)"
      ],
      "metadata": {
        "id": "KEzdEwMSV-y3"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier5.fit(count_mat_train1, labels_train)"
      ],
      "metadata": {
        "id": "rachoBPCoF1o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "9eb1286a-34eb-4200-f30d-663e76228d21"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=2.5, fit_prior=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=2.5, fit_prior=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=2.5, fit_prior=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_pred5 = classifier5.predict(count_mat_test1)"
      ],
      "metadata": {
        "id": "c9Qggt1oViN3"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat5 = confusion_matrix(labels_test, labels_pred5)\n",
        "print(conf_mat5)"
      ],
      "metadata": {
        "id": "E1bB3fxKViST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11bbbfb0-ed3c-4a90-d041-5c2a53806616"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[512  23  26  14  58]\n",
            " [ 41 158   5   9  86]\n",
            " [ 32   7 213  36  97]\n",
            " [ 15   6  18 465 106]\n",
            " [166 107 110 205 373]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance(conf_mat5)"
      ],
      "metadata": {
        "id": "a1P97o-VViWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "250c3726-1e02-410f-f4ab-e73fa19dd429"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEOPLASMS\n",
            "Accuracy: 0.87, Precision: 0.67, Recall: 0.81\n",
            "DIGESTIVE SYSTEM DISEASES\n",
            "Accuracy: 0.90, Precision: 0.52, Recall: 0.53\n",
            "NERVOUS SYSTEM DISEASES\n",
            "Accuracy: 0.89, Precision: 0.57, Recall: 0.55\n",
            "CARDIOVASCULAR DISEASES\n",
            "Accuracy: 0.86, Precision: 0.64, Recall: 0.76\n",
            "GENERAL PATHOLOGICAL CONDITIONS\n",
            "Accuracy: 0.68, Precision: 0.52, Recall: 0.39\n",
            "Total Accuracy: 0.596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again we see improved results."
      ],
      "metadata": {
        "id": "1eZ6tRxpbEJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing the general class"
      ],
      "metadata": {
        "id": "Am6kHZoNvhur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will remove the general class, and compare our optimal approaches for each embedder. This gives us a better idea of the effectiveness of each method."
      ],
      "metadata": {
        "id": "CUj0DllAUiMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filt_train = df_train[df_train['condition_label'] != 5]\n",
        "df_filt_train.reset_index(drop=True, inplace=True)\n",
        "df_filt_test = df_test[df_test['condition_label'] != 5]\n",
        "df_filt_test.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "pzuVqQyYy1WK"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corp_filt_train = df_filt_train['medical_abstract']\n",
        "corp_filt_test = df_filt_test['medical_abstract']\n",
        "labels_filt_train = df_filt_train['condition_label']\n",
        "labels_filt_test = df_filt_test['condition_label']"
      ],
      "metadata": {
        "id": "pgQTRVTty1Yx"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count Vectorizer final"
      ],
      "metadata": {
        "id": "kmMjQxr-bTig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count1 = CountVectorizer(preprocessor=preprocess4, tokenizer=tok)\n",
        "\n",
        "count_mat_train1 = count1.fit_transform(corp_filt_train)\n",
        "print(count_mat_train1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhVtVqgwy1bb",
        "outputId": "69667bf5-af4c-4802-a591-414a8db5c5b6"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7706, 21403)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_mat_test1 = count1.transform(corp_filt_test)\n",
        "print(count_mat_test1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtClWbfRy1eZ",
        "outputId": "476a03e1-ea5f-4a3e-9096-8709aa68cd06"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1927, 21403)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier6 = MultinomialNB(fit_prior=False,alpha = 2.5)"
      ],
      "metadata": {
        "id": "Y5scO08u3emO"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier6.fit(count_mat_train1, labels_filt_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "RS25_XEc3jjF",
        "outputId": "5f2f0947-8307-4e03-c098-67bf1ba4d440"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=2.5, fit_prior=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=2.5, fit_prior=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=2.5, fit_prior=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_filt_pred1 = classifier6.predict(count_mat_test1)"
      ],
      "metadata": {
        "id": "SfJW70oo3jls"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat6 = confusion_matrix(labels_filt_test, labels_filt_pred1)\n",
        "print(conf_mat6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "350ZESs73jn7",
        "outputId": "278f5e92-09f9-40c0-b80a-e8e5b4b47545"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[541  29  36  27]\n",
            " [ 48 221  11  19]\n",
            " [ 38  16 283  48]\n",
            " [ 23  20  34 533]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance(conf_mat6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLmqdwRn3erN",
        "outputId": "fcecbace-6bed-4b8d-be78-1b06b3b43fe0"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEOPLASMS\n",
            "Accuracy: 0.90, Precision: 0.83, Recall: 0.85\n",
            "DIGESTIVE SYSTEM DISEASES\n",
            "Accuracy: 0.93, Precision: 0.77, Recall: 0.74\n",
            "NERVOUS SYSTEM DISEASES\n",
            "Accuracy: 0.91, Precision: 0.78, Recall: 0.74\n",
            "CARDIOVASCULAR DISEASES\n",
            "Accuracy: 0.91, Precision: 0.85, Recall: 0.87\n",
            "Total Accuracy: 0.819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tf-Idf final"
      ],
      "metadata": {
        "id": "H24lF2mdvrSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf1 = TfidfVectorizer(preprocessor=preprocess4, tokenizer=tok)\n",
        "tfidf_mat_train1 = tfidf1.fit_transform(corp_filt_train)\n",
        "print(tfidf_mat_train1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqnNzcFC2WZC",
        "outputId": "40310906-0a9c-4da4-9bae-674b6c06054c"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7706, 21403)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_mat_test1 = tfidf1.transform(corp_filt_test)\n",
        "print(tfidf_mat_test1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi5zAhcF3KoG",
        "outputId": "5667ccdd-3851-4a94-e078-03706d41f756"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1927, 21403)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier7 = MultinomialNB(fit_prior=False,alpha = .2)"
      ],
      "metadata": {
        "id": "vB9vkmb7yBBn"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier7.fit(tfidf_mat_train1, labels_filt_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "TC0hI0ZByBFb",
        "outputId": "cdec7f3c-b294-441f-d470-1b4b46160809"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.2, fit_prior=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-23 {color: black;background-color: white;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.2, fit_prior=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.2, fit_prior=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_filt_pred2 = classifier7.predict(tfidf_mat_test1)"
      ],
      "metadata": {
        "id": "_l1uNA8xyGO-"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat7 = confusion_matrix(labels_filt_test, labels_filt_pred2)\n",
        "print(conf_mat7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06Ar-1JjyGS2",
        "outputId": "5f4509ec-f9b1-41bc-9393-ea1f749cec6a"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[517  43  42  31]\n",
            " [ 48 222   8  21]\n",
            " [ 39  18 278  50]\n",
            " [ 19  19  37 535]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance(conf_mat7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYDE1RcEyGaJ",
        "outputId": "abb8cc9a-b404-40ec-9b7e-b17c48855915"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEOPLASMS\n",
            "Accuracy: 0.88, Precision: 0.83, Recall: 0.82\n",
            "DIGESTIVE SYSTEM DISEASES\n",
            "Accuracy: 0.92, Precision: 0.74, Recall: 0.74\n",
            "NERVOUS SYSTEM DISEASES\n",
            "Accuracy: 0.90, Precision: 0.76, Recall: 0.72\n",
            "CARDIOVASCULAR DISEASES\n",
            "Accuracy: 0.91, Precision: 0.84, Recall: 0.88\n",
            "Total Accuracy: 0.805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both methods have good performance with good efficiency considering the datset is large and messy. Interestingly the simpler embedder, count vectorizer, results in better performance, this could be due to very specific medical terms occuring in a document but not throughout the class it belongs to. The inverse-document-frequency factor would then weight these highly and create noise in the data if the terms are not found across the whole class."
      ],
      "metadata": {
        "id": "8oqM3HvTd7cU"
      }
    }
  ]
}