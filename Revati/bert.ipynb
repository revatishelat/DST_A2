{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (4.36.0)\n",
      "Requirement already satisfied: torch in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (2.1.1)\n",
      "Requirement already satisfied: pandas in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (1.3.2)\n",
      "Requirement already satisfied: filelock in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets\n",
    "\n",
    "# train dataset\n",
    "train_df = pd.read_csv(\"/Users/revatishelat/Desktop/dst/assessment 2/Data/medical_tc_train.csv\")\n",
    "\n",
    "# text dataset\n",
    "test_df = pd.read_csv(\"/Users/revatishelat/Desktop/dst/assessment 2/Data/medical_tc_test.csv\")\n",
    "\n",
    "#labels \n",
    "labels_df = pd.read_csv(\"/Users/revatishelat/Desktop/dst/assessment 2/Data/medical_tc_labels.csv\")\n",
    "\n",
    "#convert dataframe to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition_label</th>\n",
       "      <th>medical_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Tissue changes around loose prostheses. A cani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Neuropeptide Y and neuron-specific enolase lev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sexually transmitted diseases of the colon, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Lipolytic factors associated with murine and h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Does carotid restenosis predict an increased r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11545</th>\n",
       "      <td>1</td>\n",
       "      <td>Epirubicin at two dose levels with prednisolon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11546</th>\n",
       "      <td>1</td>\n",
       "      <td>Four and a half year follow up of women with d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11547</th>\n",
       "      <td>5</td>\n",
       "      <td>Safety of the transbronchial biopsy in outpati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11548</th>\n",
       "      <td>3</td>\n",
       "      <td>Interictal spikes and hippocampal somatostatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11549</th>\n",
       "      <td>5</td>\n",
       "      <td>Recurrent thoracic outlet syndrome after first...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11550 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       condition_label                                   medical_abstract\n",
       "0                    5  Tissue changes around loose prostheses. A cani...\n",
       "1                    1  Neuropeptide Y and neuron-specific enolase lev...\n",
       "2                    2  Sexually transmitted diseases of the colon, re...\n",
       "3                    1  Lipolytic factors associated with murine and h...\n",
       "4                    3  Does carotid restenosis predict an increased r...\n",
       "...                ...                                                ...\n",
       "11545                1  Epirubicin at two dose levels with prednisolon...\n",
       "11546                1  Four and a half year follow up of women with d...\n",
       "11547                5  Safety of the transbronchial biopsy in outpati...\n",
       "11548                3  Interictal spikes and hippocampal somatostatin...\n",
       "11549                5  Recurrent thoracic outlet syndrome after first...\n",
       "\n",
       "[11550 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition_label</th>\n",
       "      <th>medical_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Obstructive sleep apnea following topical orop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Neutrophil function and pyogenic infections in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>A phase II study of combined methotrexate and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Flow cytometric DNA analysis of parathyroid tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Paraneoplastic vasculitic neuropathy: a treata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>4</td>\n",
       "      <td>Management of aortobronchial fistula with graf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>5</td>\n",
       "      <td>Tuberculous psoas muscle abscess following che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>4</td>\n",
       "      <td>Clinical evaluation of high-frequency (ultraso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>1</td>\n",
       "      <td>Antitumor activity of liposome-encapsulated do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>4</td>\n",
       "      <td>An unusual venous anomaly of the placenta. The...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2888 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      condition_label                                   medical_abstract\n",
       "0                   3  Obstructive sleep apnea following topical orop...\n",
       "1                   5  Neutrophil function and pyogenic infections in...\n",
       "2                   5  A phase II study of combined methotrexate and ...\n",
       "3                   1  Flow cytometric DNA analysis of parathyroid tu...\n",
       "4                   4  Paraneoplastic vasculitic neuropathy: a treata...\n",
       "...               ...                                                ...\n",
       "2883                4  Management of aortobronchial fistula with graf...\n",
       "2884                5  Tuberculous psoas muscle abscess following che...\n",
       "2885                4  Clinical evaluation of high-frequency (ultraso...\n",
       "2886                1  Antitumor activity of liposome-encapsulated do...\n",
       "2887                4  An unusual venous anomaly of the placenta. The...\n",
       "\n",
       "[2888 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition_label</th>\n",
       "      <th>condition_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>neoplasms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>digestive system diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>nervous system diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>cardiovascular diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>general pathological conditions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   condition_label                   condition_name\n",
       "0                1                        neoplasms\n",
       "1                2        digestive system diseases\n",
       "2                3          nervous system diseases\n",
       "3                4          cardiovascular diseases\n",
       "4                5  general pathological conditions"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df[\"medical_abstract\"] # 11550\n",
    "train_labels = train_df[\"condition_label\"]\n",
    "\n",
    "test_texts = test_df[\"medical_abstract\"]  # 2888\n",
    "test_labels = test_df[\"condition_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Tissue changes around loose prostheses. A cani...\n",
       "1        Neuropeptide Y and neuron-specific enolase lev...\n",
       "2        Sexually transmitted diseases of the colon, re...\n",
       "3        Lipolytic factors associated with murine and h...\n",
       "4        Does carotid restenosis predict an increased r...\n",
       "                               ...                        \n",
       "11545    Epirubicin at two dose levels with prednisolon...\n",
       "11546    Four and a half year follow up of women with d...\n",
       "11547    Safety of the transbronchial biopsy in outpati...\n",
       "11548    Interictal spikes and hippocampal somatostatin...\n",
       "11549    Recurrent thoracic outlet syndrome after first...\n",
       "Name: medical_abstract, Length: 11550, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_texts)\n",
    "train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df[\"medical_abstract\"].astype(str).tolist() # 11550\n",
    "train_labels = train_df[\"condition_label\"].astype(int).tolist()\n",
    "\n",
    "test_texts = test_df[\"medical_abstract\"].astype(str).tolist()  # 2888\n",
    "test_labels = test_df[\"condition_label\"].astype(int).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_texts)\n",
    "# train_texts #outputs all teh text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to list\n",
    "# train_texts = train_texts.tolist()\n",
    "\n",
    "# labels = df['label'].astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(set(labels)))\n",
    "\n",
    "# Tokenize and encode the input text\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  8153,  3431,  ...,     0,     0,     0],\n",
       "        [  101, 11265, 10976,  ...,     0,     0,     0],\n",
       "        [  101, 12581, 11860,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  3808,  1997,  ...,     0,     0,     0],\n",
       "        [  101,  6970,  2594,  ...,     0,     0,     0],\n",
       "        [  101, 28667, 29264,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        list\n",
      "\u001b[0;31mString form:\u001b[0m [5, 1, 2, 1, 3, 3, 2, 4, 5, 5, 4, 1, 5, 1, 4, 2, 1, 4, 5, 1, 5, 1, 5, 1, 5, 2, 3, 4, 2, 1, 3, 4,  <...> , 5, 5, 5, 3, 4, 5, 1, 3, 1, 4, 4, 4, 1, 4, 3, 1, 2, 4, 5, 5, 3, 3, 5, 4, 5, 4, 5, 1, 1, 5, 3, 5]\n",
      "\u001b[0;31mLength:\u001b[0m      11550\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "Built-in mutable sequence.\n",
      "\n",
      "If no argument is given, the constructor creates a new empty list.\n",
      "The argument must be an iterable if specified."
     ]
    }
   ],
   "source": [
    "?train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  8153,  3431,  ...,     0,     0,     0],\n",
       "        [  101, 11265, 10976,  ...,     0,     0,     0],\n",
       "        [  101, 12581, 11860,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  3808,  1997,  ...,     0,     0,     0],\n",
       "        [  101,  6970,  2594,  ...,     0,     0,     0],\n",
       "        [  101, 28667, 29264,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets\n",
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(train_labels))\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training dataset into training and validation sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for training, validation, and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/revatishelat/opt/anaconda3/envs/PY396/lib/python3.9/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1155 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1155 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 3 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/revatishelat/Desktop/dst/assessment 2/bert1.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/revatishelat/Desktop/dst/assessment%202/bert1.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m input_ids, attention_mask, labels \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mto(device), attention_mask\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/revatishelat/Desktop/dst/assessment%202/bert1.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/revatishelat/Desktop/dst/assessment%202/bert1.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(input_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask, labels\u001b[39m=\u001b[39;49mlabels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/revatishelat/Desktop/dst/assessment%202/bert1.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/revatishelat/Desktop/dst/assessment%202/bert1.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PY396/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PY396/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PY396/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1599\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1597\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mproblem_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msingle_label_classification\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1598\u001b[0m     loss_fct \u001b[39m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m-> 1599\u001b[0m     loss \u001b[39m=\u001b[39m loss_fct(logits\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_labels), labels\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m   1600\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mproblem_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulti_label_classification\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1601\u001b[0m     loss_fct \u001b[39m=\u001b[39m BCEWithLogitsLoss()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PY396/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PY396/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PY396/lib/python3.9/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1180\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1181\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PY396/lib/python3.9/site-packages/torch/nn/functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3052\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3053\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 3 is out of bounds."
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on validation set\n",
    "model.eval()\n",
    "val_preds = []\n",
    "val_true = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        \n",
    "        val_preds.extend(preds)\n",
    "        val_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Validation Accuracy:\", accuracy_score(val_true, val_preds))\n",
    "print(\"Classification Report:\\n\", classification_report(val_true, val_preds))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on test set\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_true = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        \n",
    "        test_preds.extend(preds)\n",
    "        test_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Test Accuracy:\", accuracy_score(test_true, test_preds))\n",
    "print(\"Classification Report:\\n\", classification_report(test_true, test_preds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY396",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
