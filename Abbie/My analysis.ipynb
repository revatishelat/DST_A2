{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1cf459b",
   "metadata": {},
   "source": [
    "# Creating a CNN model \n",
    "1. Implement  initial preprocessing phase\n",
    "2. Run Word2Vec\n",
    "3. Create CNN model    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6528a0d1",
   "metadata": {},
   "source": [
    "## Any pre-required install ments \n",
    "* Edit so formal 'if requires package statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d52a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "#!pip install gensim\n",
    "#!pip install torch\n",
    "\n",
    "#!pip install torch torchvision torchaudio\n",
    "#import torch\n",
    "## For windows (possibly):\n",
    "#!conda install -y -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\n",
    "# Anything above 2.10 is not supported on the GPU on Windows Native\n",
    "#!pip install \"tensorflow<2.11\"\n",
    "\n",
    "#!pip install typing-extensions --upgrade\n",
    "#!pip install Cython\n",
    "#!conda install -y -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\n",
    "## Anything above 2.10 is not supported on the GPU on Windows Native\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f8d09e",
   "metadata": {},
   "source": [
    "## Package imports required\n",
    "* Edit for formal 'if requires package' statement\n",
    "* See if can remove pink output/ error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0dc401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbie\\Documents\\programming\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\abbie\\Documents\\programming\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import requests\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cefcb3",
   "metadata": {},
   "source": [
    "## Downloading and refining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "906d1400",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('medical_tc_train.csv')\n",
    "test_data = pd.read_csv('medical_tc_test.csv')\n",
    "labels = pd.read_csv('medical_tc_labels.csv')\n",
    "test_data.head()\n",
    "train_data['index'] = train_data.index\n",
    "\n",
    "text_train = train_data['medical_abstract']# preprocess is faster than normalise_text.\n",
    "y_train = train_data['condition_label']\n",
    "text_train[:2]\n",
    "text_test = test_data['medical_abstract']\n",
    "y_test = test_data['condition_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd94df",
   "metadata": {},
   "source": [
    "## Preprocessing text\n",
    "* Put all preporcessing into one cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e511baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function from preprocessing file \n",
    "### Do this once! Then leave commented next time you run the script.\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('popular')\n",
    "\n",
    "en_stop = set(stopwords.words('english'))\n",
    "def preprocess(data):\n",
    "    data_proc = []\n",
    "    for doc in data['medical_abstract']:\n",
    "        #lowercases document\n",
    "        doc = doc.lower()\n",
    "        #removes any non-letter characters\n",
    "        doc = re.sub(r'\\b[^a-zA-Z]+\\b', ' ', doc)\n",
    "        #tokenize\n",
    "        toks = nltk.word_tokenize(doc)\n",
    "        #remove tokens of lenth <= 1 (can be varied)\n",
    "        toks = [tok for tok in toks if len(tok) > 1]\n",
    "        #remove stopwords\n",
    "        toks = [tok for tok in toks if tok not in en_stop]\n",
    "        #lemmatize\n",
    "        toks = [WordNetLemmatizer().lemmatize(tok) for tok in toks]\n",
    "        data_proc.append(toks)\n",
    "    return data_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a46b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tissue', 'change', 'around', 'loose', 'prosthesis', 'canine', 'model', 'investigate', 'effect', 'antiinflammatory', 'agent', 'aseptically', 'loosened', 'prosthesis', 'provided', 'mean', 'investigating', 'vivo', 'vitro', 'activity', 'cell', 'associated', 'loosening', 'process', 'seven', 'dog', 'cell', 'isolated', 'maintained', 'culture', 'sufficient', 'period', 'time', 'biologic', 'activity', 'could', 'studied', 'well', 'effect', 'different', 'agent', 'added', 'cell', 'vivo', 'vitro', 'biologic', 'response', 'determined', 'interleukin', 'prostaglandin', 'e2', 'activity', 'paralleled', 'roentgenographic', 'appearance', 'loosening', 'technetium', 'image', 'observation', 'made', 'time', 'revision', 'surgery', 'correlation', 'clinical', 'roentgenographic', 'histologic', 'biochemical', 'loosening', 'indicates', 'canine', 'model', 'suitable', 'investigating', 'mechanism', 'prosthetic', 'failure', 'canine', 'model', 'permit', 'study', 'possible', 'nonsurgical', 'therapeutic', 'intervention', 'ultimate', 'hope', 'stopping', 'slowing', 'loosening', 'process']\n",
      "[   75    48  1726  6540  1121  1911   211  1094    17  5967   269 23060\n",
      " 16264  1121   907    20  6541   626   446    91     3    21  4207   635\n",
      "   175   467     3   451  1020   563  1775   101    38  2170    91   196\n",
      "   105   129    17   184   269  1802     3   626   446  2170    55   365\n",
      "  1247  1344  2201    91  5019  4611   925  4207  2108   664   588   485\n",
      "    38  1747    46   281    18  4611   429  1287  4207  1598  1911   211\n",
      "  2092  6541   248  1828   111  1911   211  2469     5   294  4208   569\n",
      "   509  4798  5795  4612  4906  4207   635     0     0     0     0     0\n",
      "     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_trains  = preprocess(train_data)\n",
    "X_tests = preprocess(test_data)\n",
    "print(X_trains[0])\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_trains)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_trains)\n",
    "X_test = tokenizer.texts_to_sequences(X_tests)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_length = 100\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
    "print(X_train[0])\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding='post')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6548fc",
   "metadata": {},
   "source": [
    "## Word2Vec model\n",
    "* Consider what each line of code is doing to refine to make sense in context, i.e. is sentence needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4765492c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=30615, vector_size=100, alpha=0.025>\n",
      "(30616, 100)\n"
     ]
    }
   ],
   "source": [
    "# Train the Word2Vec model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "w2v_model = Word2Vec(X_trains, vector_size=100, window=5, min_count=1, workers=4)\n",
    "print(w2v_model)\n",
    "#w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)\n",
    "\n",
    "\n",
    "# Create a weight matrix for the embedding layer\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]        \n",
    "print(embedding_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e431b",
   "metadata": {},
   "source": [
    "## Evaluation metrics \n",
    "* Accuracy \n",
    "* Time to run / comparing to other models and on GPU maybe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d829ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy (source mrdbuorke colab link)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e6d9346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time on cpu: 0.000 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00015229999996790866"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float,\n",
    "                     end: float,\n",
    "                     device: torch.device = None):\n",
    "  \"\"\"Prints difference between start adn end time. \"\"\"\n",
    "  total_time = end - start\n",
    "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "  return total_time\n",
    "\n",
    "start_time = timer()\n",
    "# some code...\n",
    "end_time = timer()\n",
    "print_train_time(start=start_time, end= end_time, device = \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018d331",
   "metadata": {},
   "source": [
    "## CNN model creation\n",
    "\n",
    "* Print out accuracy \n",
    "* Print out predictions vs truths i.e confusion matrix format\n",
    "* Add time it function \n",
    "* Grid search for best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b7552e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes =5\n",
    "#create vector of labels 0,4\n",
    "\n",
    "\n",
    "class CNNMulticlass(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, embedding_matrix, max_length):\n",
    "        super(CNNMulticlass, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False #keeps embedidng matrix\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(embedding_dim, 256, kernel_size=2)\n",
    "        self.pool1 = nn.MaxPool1d(5)\n",
    "        self.conv2 = nn.Conv1d(256, 256, kernel_size=2)\n",
    "        self.pool2 = nn.MaxPool1d(5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256 * ((max_length - 4) // 25) , 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)  \n",
    "        x = self.pool1(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool2(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "                                                          \n",
    "        return x\n",
    "\n",
    "\n",
    "# Create an instance of the CNN model\n",
    "model_multiclass = CNNMulticlass(vocab_size, 100, embedding_matrix, max_length)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model_multiclass.parameters())\n",
    "optimizer2 = torch.optim.SGD(params = model_multiclass.parameters(),\n",
    "                            lr =0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Convert data to PyTorch tensors and create DataLoader\n",
    "X_train_tensor = torch.LongTensor(X_train)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "X_test_tensor = torch.LongTensor(X_test)\n",
    "#print(X_test_tensor[0])\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "#note batch size 32 is common pracitce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8244729",
   "metadata": {},
   "source": [
    "### Creating a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c7ad039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8cdc4423a164e31880b2b6f63c9f914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "-----\n",
      "\n",
      "Train loss: 1.1305 | Test loss: 1.0568, Test acc: 55.4602\n",
      "Train time on cpu: 44.210 seconds\n",
      "Epoch:1\n",
      "-----\n",
      "\n",
      "Train loss: 0.9889 | Test loss: 1.0307, Test acc: 57.3146\n",
      "Train time on cpu: 96.995 seconds\n",
      "Epoch:2\n",
      "-----\n",
      "\n",
      "Train loss: 0.9343 | Test loss: 1.0349, Test acc: 57.8297\n",
      "Train time on cpu: 151.254 seconds\n",
      "Epoch:3\n",
      "-----\n",
      "\n",
      "Train loss: 0.8874 | Test loss: 1.0528, Test acc: 57.1085\n",
      "Train time on cpu: 197.248 seconds\n",
      "Epoch:4\n",
      "-----\n",
      "\n",
      "Train loss: 0.8342 | Test loss: 1.1935, Test acc: 56.1470\n",
      "Train time on cpu: 252.814 seconds\n",
      "Epoch:5\n",
      "-----\n",
      "\n",
      "Train loss: 0.7712 | Test loss: 1.3179, Test acc: 54.4643\n",
      "Train time on cpu: 299.796 seconds\n",
      "Epoch:6\n",
      "-----\n",
      "\n",
      "Train loss: 0.7119 | Test loss: 1.4558, Test acc: 53.0220\n",
      "Train time on cpu: 338.468 seconds\n",
      "Epoch:7\n",
      "-----\n",
      "\n",
      "Train loss: 0.6703 | Test loss: 1.5766, Test acc: 52.0948\n",
      "Train time on cpu: 386.239 seconds\n",
      "Epoch:8\n",
      "-----\n",
      "\n",
      "Train loss: 0.6226 | Test loss: 1.7303, Test acc: 50.6181\n",
      "Train time on cpu: 429.974 seconds\n",
      "Epoch:9\n",
      "-----\n",
      "\n",
      "Train loss: 0.5873 | Test loss: 1.9373, Test acc: 48.9354\n",
      "Train time on cpu: 478.011 seconds\n",
      "Epoch:10\n",
      "-----\n",
      "\n",
      "Train loss: 0.5331 | Test loss: 2.0176, Test acc: 47.3558\n",
      "Train time on cpu: 539.812 seconds\n",
      "Epoch:11\n",
      "-----\n",
      "\n",
      "Train loss: 0.4791 | Test loss: 2.5006, Test acc: 45.7074\n",
      "Train time on cpu: 588.983 seconds\n",
      "Epoch:12\n",
      "-----\n",
      "\n",
      "Train loss: 0.4355 | Test loss: 2.5824, Test acc: 43.3036\n",
      "Train time on cpu: 642.535 seconds\n",
      "Epoch:13\n",
      "-----\n",
      "\n",
      "Train loss: 0.4365 | Test loss: 2.8562, Test acc: 44.6085\n",
      "Train time on cpu: 694.176 seconds\n",
      "Epoch:14\n",
      "-----\n",
      "\n",
      "Train loss: 0.4000 | Test loss: 2.7232, Test acc: 44.4712\n",
      "Train time on cpu: 738.095 seconds\n",
      "Epoch:15\n",
      "-----\n",
      "\n",
      "Train loss: 0.3708 | Test loss: 2.4765, Test acc: 45.1923\n",
      "Train time on cpu: 786.503 seconds\n",
      "Epoch:16\n",
      "-----\n",
      "\n",
      "Train loss: 0.3526 | Test loss: 2.6013, Test acc: 43.7157\n",
      "Train time on cpu: 843.163 seconds\n",
      "Epoch:17\n",
      "-----\n",
      "\n",
      "Train loss: 0.3324 | Test loss: 2.6656, Test acc: 42.2734\n",
      "Train time on cpu: 895.485 seconds\n",
      "Epoch:18\n",
      "-----\n",
      "\n",
      "Train loss: 0.3205 | Test loss: 2.5487, Test acc: 43.8187\n",
      "Train time on cpu: 948.422 seconds\n",
      "Epoch:19\n",
      "-----\n",
      "\n",
      "Train loss: 0.3029 | Test loss: 2.6978, Test acc: 42.9945\n",
      "Train time on cpu: 1017.779 seconds\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "print(len(test_loader))\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "epochs = 20\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch:{epoch}\\n-----\")\n",
    "    train_loss = 0\n",
    "    for batch, (inputs, labels) in enumerate(train_loader):\n",
    "        model_multiclass.train()\n",
    "        # Forward pass'=\n",
    "        #print(inputs)\n",
    "        y_pred = model_multiclass(inputs)\n",
    "        #print(y_pred.softmax(dim=1))\n",
    "        #Calculate loss\n",
    "        labels = labels.long() -1\n",
    "        #print(labels)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        train_loss += loss\n",
    "        #optimizer zero-grad\n",
    "        optimizer.zero_grad()\n",
    "        #loss backward      \n",
    "        loss.backward()\n",
    "        #step\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    ### Testing\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_multiclass.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test_tensor, y_test_tensor in test_loader:\n",
    "            #forward pass\n",
    "            test_pred = model_multiclass(X_test_tensor)\n",
    "            #print(y_test_tensor -1)[0,4]\n",
    "            #calculate loss\n",
    "            y_test_tensor = y_test_tensor-1 #.Long() \n",
    "            test_loss += criterion(test_pred, y_test_tensor)\n",
    "            #calculate accuracy \n",
    "            y_preds = test_pred.argmax(dim=1)\n",
    "            #print(y_preds)\n",
    "            test_acc += accuracy_fn(y_true = y_test_tensor, y_pred = y_preds)\n",
    "        # Calculate the test loss average per batch\n",
    "        test_loss /= len(test_loader)\n",
    "        \n",
    "        # Calculate the test acc average per batch\n",
    "        test_acc /= len(test_loader)\n",
    "            \n",
    "        \n",
    "        \n",
    "    print(f\"\\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n",
    "    train_time_end_on_cpu = timer()\n",
    "    total_train_time_model_multiclass = print_train_time(start = train_time_start_on_cpu,\n",
    "                                              end = train_time_end_on_cpu,\n",
    "                                              device=str(next(model_multiclass.parameters()).device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39823c00",
   "metadata": {},
   "source": [
    "## Evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc9da923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'CNNMulticlass',\n",
       " 'model_loss': 2.6977672576904297,\n",
       " 'model_acc': 8.82554945054945}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn : torch.nn.Module,\n",
    "               accuracy_fn):\n",
    "  \"\"\" Returns a dictionary containing the results pf model prediction on data_loader\"\"\"\n",
    "  loss, acc = 0, 0\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    for X, y in data_loader:\n",
    "      # Make predictions\n",
    "      y_pred = model(X)\n",
    "\n",
    "      # Accumulate the loss and acc values per batch\n",
    "      loss += loss_fn(y_pred, y-1)\n",
    "      acc += accuracy_fn(y_true = y,\n",
    "                         y_pred = y_pred.argmax(dim =1))\n",
    "\n",
    "    # Scale loss and acc to find average loss/acc per batch\n",
    "    loss /= len(data_loader)\n",
    "    acc /= len(data_loader)\n",
    "\n",
    "  return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "          \"model_loss\": loss.item(),\n",
    "          \"model_acc\": acc}\n",
    "\n",
    "#Calculate model 0 results on test dataset\n",
    "model_multiclass_results = eval_model(model=model_multiclass,\n",
    "                             data_loader = test_loader,\n",
    "                             loss_fn = criterion,\n",
    "                             accuracy_fn = accuracy_fn)\n",
    "model_multiclass_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "652367fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c4ef8417244e15b644fa08ab105da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making predictions...:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlxtend version: 0.23.0\n",
      "tensor([3, 5, 5,  ..., 4, 1, 4])\n",
      "tensor([5, 1, 1,  ..., 5, 2, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbie\\Documents\\programming\\lib\\site-packages\\mlxtend\\plotting\\plot_confusion_matrix.py:102: RuntimeWarning: invalid value encountered in divide\n",
      "  normed_conf_mat = conf_mat.astype(\"float\") / total_samples\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAGpCAYAAADGJ5LWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6UklEQVR4nO3dd3gU5cLG4d8bloQaaggkoXdClSAdQRBFmmABbCAWVCxYQBQLoh4LFo5dVI54UMCOShEsSFGp0qRXSUKvSSgJm/f7Y9dIP3yY2RnY576uXOzOzO48b0j22SmZNdZaREREvCLC7QAiIiJHUzGJiIinqJhERMRTVEwiIuIpKiYREfEUn9sBjlayZElbvnwFt2OIiIjDNm3ayM6dO83J5nmqmMqXr8DsOfPdjiEiIg5r3jjplPO0K09ERDxFxSQiIp6iYhIREU9RMYmIiKeomERExFNUTCIi4ikqJhER8RQVk4iIeIqKSUREPEXFJCIinqJiEhERT1ExiYiIp6iYRETEU1RMIiLiKSomERHxFBWTiIh4iopJREQ8RcUkIiKeomISERFPUTGJiIinqJhERMRTVEwiIuIpKiYREfEUFZOIiHiKiklERDxFxSQiIp6iYgKmfjeFuonVSaxRheEvPOd2nJAK57FDeI9fYw/PsYP3x+9oMRljLjPGrDLGrDXGDHZyXWfL7/cz4J7+TPhmMr8vWc6n48ayYvlyt2OFRDiPHcJ7/Bp7eI4dzo3xO1ZMxpg8wBtAB6AW0MsYU8up9Z2teXPnUrlyFSpWqkRkZCRX9+jJt99McDtWSITz2CG8x6+xh+fY4dwYv5NbTBcCa6216621mcA4oKuD6zsrqakpJCSUzbkfH59ASkqKi4lCJ5zHDuE9fo09PMcO58b4nSymeGDzUfeTg9OOYYy5zRgz3xgzf8fOHQ7GOTlr7QnTjDEhz+GGcB47hPf4NfZjhcvY4dwYv5PFdLKRnvAdsdaOtNYmWWuTYkrGOBjn5OLjE0hO/rs/U1KSiYuLC3kON4Tz2CG8x6+xh+fY4dwYv5PFlAyUPep+ApDq4PrOSlKjRqxdu4aNGzaQmZnJp+PH0bFTF7djhUQ4jx3Ce/wae3iOHc6N8fscfO55QFVjTEUgBegJXOvg+s6Kz+fjlX+/TueOl+L3++ndpy+1EhPdjhUS4Tx2CO/xa+zhOXY4N8ZvTra/Mdee3JjLgRFAHmCUtfaZ0y3fsGGSnT1nvmN5RETEG5o3TmLBgvknPbjl5BYT1tpJwCQn1yEiIucXXflBREQ8RcUkIiKeomISERFPUTGJiIinqJhERMRTVEwiIuIpKiYREfEUFZOIiHiKiklERDxFxSQiIp6iYhIREU9RMYmIiKeomERExFNUTCIi4ikqJhER8RQVk4iIeIqKSUREPEXFJCIinqJiEhERT1ExiYiIp6iYRETEU1RMIiLiKSomERHxFBWTiIh4iopJREQ8xed2AAko1uVVtyO4atabfdyO4Jq0w1luR3BVYly02xFc0+b56W5HcM261P2nnKctJhER8RQVk4iIeIqKSUREPEXFJCIinqJiEhERT1ExiYiIp6iYRETEU1RMIiLiKSomERHxFBWTiIh4iopJREQ8RcUkIiKeomISERFPUTGJiIinqJhERMRTVEwiIuIpKiYREfEUFZOIiHiKiklERDxFxSQiIp6iYhIREU9RMYmIiKeomERExFNUTCIi4ikqJhER8RQVk4iIeIqKSUREPMXndgAvmPrdFB68/178fj99+t7CwEGD3Y6UqxJKFuK9B9oTW6wA2dYyasoy3piwGIA7Otfl9s71OOLPZsq8jQwZNTvncWVjCrHw7et55qM5jPjid7fi56q0/Xt56qG7Wbd6BcYYHn/hDWb/NJWfp00iIiKCYiVKMvTFt4iJLeN21Fz35/o1DLv/1pz7WzZv5KZ7BlO/cQteeeJBDh7IoHR8WYa8+A4FCxV2Makz7r3zVqZNmUTJmBhmzFkEwLKlixk44C4OZKRTtlx53nrvQwpHR7sbNJeULhLFv66sTclCkWRb+Gx+MmN+3Ux0fh8v9ahLXNH8pO49yAPjlrD/0BF8EYYnu9WiZpnC+CIMXy/awnszNrqS3VhrnXliY0YBnYDt1traZ/KYhg2T7Ow58x3Jcyp+v586taoxcfI04hMSaNGkEaPHjKVmrVohzVGsy6uOPXfpYgUoXbwgi9btoFD+vPzyak+uGTaRUsUK8FCPJLo98Q2ZR/zEFMnPjn0Hcx43dsjlZGdb5q3a6ngxzXqzj6PP/5cnHridBo2ackXP3mRlZnLo0AGMiaBQ4cCL0bj/vM36tSt55JkRIckDkHY4K2Tr+ovf7+fqi+rw5vjvGHrvTdw+6EnqX9icSZ9/xNbkP+l778Mhy5IYF5oi+HX2TAoWLMRd/W7KKab2FzVl6DPP06xFKz7+7wf8uXEDgx97MiR5ANo8P92x5y5ZKJKYwlGs2JJGgcg8fHJnY+75aDFXXBDHvoNZvD9jIze3qkB0Ph+vTF3L5XVL06ZGDAM/WUq+vBFMuKcZN70/n9S9hxzJt+79/hzcstqcbJ6Tu/I+AC5z8Plzxby5c6lcuQoVK1UiMjKSq3v05NtvJrgdK1dt3XOARet2AJB+MIuVf+4hrmRBbutYhxc/XUDmET/AMaXUuWklNmzZx/I/d7uS2Qnpafv5fe5suva4EYC8kZEUji6aU0oABw9mYMxJf1fOKwt/nUFc2QqUji/L5g1rqdeoGQBJzVozY+o3LqdzRtPmLSlarNgx09auXU3T5i0BuKhNW779+ks3ojliZ3omK7akAXAg08/6HRnERkfRpkYMExamAjBhYSoX1ywFgAXyR+YhT4QhypeHLH826YePuJLdsWKy1s4APP+qlpqaQkJC2Zz78fEJpKSkuJjIWeVKFaZ+5RjmrdxGlbiiNE+MY8Yr1zD1+StpWDXwA1ogyscDVzXkmY/nupw2d6Vs3kjR4iV5cuCdXNuxBU89dBcHD2QA8MbwYXRsVovJEz7l9vuGuJzUeT9O+pK2HbsDULFqTWb/OBmA6VMmsH3L+fvzf7waNROZMilQxF9/9TkpKckuJ3JGXNF81CxTmCXJ+yhRKJKd6ZlAoLyKF4oEYNqybRzM9PPTQ62YNrAlH8zaxP6D51kxnSljzG3GmPnGmPk7du4I+fpPtivzfH3HXDBfXsYO6cjAkTNIO5iJL08ExQpF0eq+T3jk/VmMebgDAI9d34TXvlpExqHQ72Jykv/IEVb9sZirrruZjyfOIn+Bgnzw1isA9B/4OBN/WU6HrlfzyYcjXU7qrKzMTH75cQoXXdYFgEH/epUJH43itu4XczAjnbx5I11OGDr/fnMko0a+TbtWjUlPSyPyPBx7/sg8vNKrHs9PWk3GYf8pl6uTEI3fWi5+fgaXvTST3s3Lk1AsfwiT/s31kx+stSOBkRA4xhTq9cfHJ5CcvDnnfkpKMnFxcaGO4ThfngjGDrmc8dNXMeGXdQCk7Eznq+Dt+au3kW2hZHR+GlWPpVuLKjzTtzlFCkaRbS2HMv28/e0SN4fwj5UqE0+p0vHUbpAEQNsOXfng7VeOWeayLldz783X0O++R9yIGBJzZn5PtVp1KV4ysIVcrlJVho/6DIDNG9by28/T3IwXUlWr1eDTCZMAWLdmNd9/N9nlRLnLF2EY0asuExdv4fvl2wHYlZ5JyeBWU8lCkewObj1dXrcMs9fs4ki2ZXdGFov+3EtifDTJew6ebhWOcH2LyW1JjRqxdu0aNm7YQGZmJp+OH0fHTl3cjpXr3h7QllWbd/Pql3+fxPDNb+toXS8BgCrxRYn0RbBz/0HaDfqcGjd9QI2bPuD1CYsYPn7eOV9KACVjYoktE8/GdWsAmPvLz1SqUp0/N6zLWebn7ydToVJVtyKGxI8Tv+Di4G48gD27AnsqsrOz+e/bL9O5Zx+XkoXejh2BF+vs7GxeHv4svW++zeVEuWtYt1qs35HBh7/8mTNt+soddL0g8Oa76wVx/LQy8P+/Zd8hLqwUOAaXP28EdcsWYcOOjNCHxgNbTG7z+Xy88u/X6dzxUvx+P7379KVWYqLbsXJVs1pluK5tTZZu2Mlvr/UC4InRvzB66nLeGdCO+W9eR+YRP7e8fP6/Ux745As8dt8tZGVmEV+uAk8Mf4OnBt/NpvVriTARlIkvy8PPvPK/n+gcdejgARbM/pn7n3w5Z9oPE79gwkfvA9CyfSc6dL/WrXiO6nfT9cyeNYPdu3ZSr0ZFBj3yOBnp6Yx69y0AOna5gl7X93Y5Ze5pUL4oXRrEsXprGp/1bwLAv6et5b0ZG3mpZx26XxDPln0HuX9c4E3n2Dmbebp7Il/d3RRj4KuFqazelu5KdidPFx8LtAZKAtuAJ6y175/uMW6cLu4VTp4ufi4I1eniXuTG6eJeEqrTxb3IydPFve50p4s7tsVkre3l1HOLiMj5K+yPMYmIiLeomERExFNUTCIi4ikqJhER8RQVk4iIeIqKSUREPEXFJCIinqJiEhERT1ExiYiIp6iYRETEU1RMIiLiKSomERHxFBWTiIh4iopJREQ8RcUkIiKeomISERFPUTGJiIinqJhERMRTVEwiIuIpKiYREfEUFZOIiHiKiklERDxFxSQiIp6iYhIREU9RMYmIiKeomERExFN8bgeQgI3j7nA7gque+XGt2xFcM/SSqm5HcJV1O4CLHule0+0Irnn0i3ynnKctJhER8RQVk4iIeIqKSUREPEXFJCIinqJiEhERT1ExiYiIp6iYRETEU1RMIiLiKSomERHxFBWTiIh4iopJREQ8RcUkIiKeomISERFPUTGJiIinqJhERMRTVEwiIuIpKiYREfEUFZOIiHiKiklERDxFxSQiIp6iYhIREU9RMYmIiKeomERExFNUTCIi4ikqJhER8RQVk4iIeIqKSUREPEXFBEz9bgp1E6uTWKMKw194zu04jkpJ3kz3TpfQslEdWjWux7tvvQbA119+RqvG9ShTNIpFCxe4nDJ3ff/aEN7r3YKP7ulywryFX43itW61OLh/DwD7t6fwZo8GjL2vG2Pv68ZPbw0NcVrn3H3HLVSvEEfzRvVPmPf6v1+mRKG87Nq5M/TBQuSeO26hRoU4Whw1/uefGUbtquVp3bQhrZs2ZNp3k90LmMtGPvkAd7Srz0PXtM2Zlr5vD8/eeS33X9GSZ++8loz9e495zM4tKfRtUZ2JH74d4rTHcqyYjDFljTE/GWNWGGP+MMbc69S6/gm/38+Ae/oz4ZvJ/L5kOZ+OG8uK5cvdjuUYn8/H0KdfYOa8pUz6fhb/efctVq1cTo1aiYwa8wlNmrd0O2Kuq3lxN7o8PvKE6Wk7t7B58a8UjilzzPQisWXp9cqX9HrlS9rcMTREKZ3X67refPLVtydMT0nezPQfvyehbDkXUoVOz+t6M/4k47/9rnuZ/usCpv+6gEsu7eBCMme07Hw1g1777zHTvv7gTRIbNeflr2aS2Kg5X3/w5jHzx7z8JPWatQllzJNycovpCPCAtbYm0ATob4yp5eD6zsq8uXOpXLkKFStVIjIykqt79OTbbya4HcsxsaXLULd+AwAKFS5M1eo12JqaSrXqNalStbrL6ZwRn5hEvsJFTpg+c9TzNLvxAcCEPpQLmrVoSbFixU+YPuShBxn69LMYc35/H041/vNVzQuaUKhI0WOmLfx5Ki07XQVAy05XsWD6dznz5v80hVLx5UioXC2UMU/KsWKy1m6x1i4M3k4DVgDxTq3vbKWmppCQUDbnfnx8AikpKS4mCp0/N21k2ZLFXJB0odtRQm793B8pVLwUMRVrnDBv//YUxt7fnc+H3EjK8vkupAudyRO/oUxcHLXr1HM7imvef+dNWjVuwD133MLePXvcjuOofbt2UiwmFoBiMbHs270LgEMHD/DN6Lfoftt9bsbLEZJjTMaYCkADYM5J5t1mjJlvjJm/Y+eOUMQ5hrX2hGnn+ztHgIz0dG65oQfDnn2RwtHRbscJqazDB5n/2Ts07nX3CfMKFouhz8gf6PXyF7Ts+xBTXx5E5oF0F1I678CBA7w8/FkefnSo21Fcc9Mt/Zi/dBXTf11AbGwZHn9koNuRXPH52y/R4dpbyFegoNtRAPA5vQJjTCHgc2CAtXb/8fOttSOBkQANGyad2BIOi49PIDl5c879lJRk4uLiQh0jpLKysrj5hh50v6YXHbt0cztOyO3bupn921IYe19g7Om7tjHugSu55oXxFCwWQ/68kQCUqpxIkdJl2ZO6kdgqtd2M7IiN69fx58aNtGraEIDUlGTatLiQaT//QmxsaZfThUap2Nic2zfcdDPXXnWFe2FCoEiJkuzZsY1iMbHs2bGNIsVLALBu2e/M/WESY1/9FwfS9mMiDHmj8tG+Rx9XcjpaTMaYvARK6SNr7RdOrutsJTVqxNq1a9i4YQNx8fF8On4cH/z3Y7djOcZay3133UbV6jW4/a4BbsdxRcny1bhl9Kyc+x/c1o4eL35K/uhiHNy3m6hCRYjIk4d9Wzezd8smisQmuJjWObVq12HVxtSc+/VrVeGHGb9RomRJF1OF1tatWyhdOnDyy8RvvqJGrUSXEznrglaXMPPbz+hyU39mfvsZF1zUHoDH3//75fnzd14mX/4CrpUSOFhMJrA/7H1ghbX2ZafW80/5fD5e+ffrdO54KX6/n959+lIr8fz94Zz72y98Nu4jaibWpm2LJAAefvwpMg8fZsig+9i1cwfXX9OV2nXqMe7LiS6nzR1TXnqQlD/mcmj/Xkbd0obGPe8isd2VJ102Zfl85ox9DZPHR0REBG1uf4J8hYuGNrBDbu1zPbNn/syuXTupXa0Cg4c8zvW9+7odK2T+Gv/uXTupU60CDw15nNkzf2bZksUYYyhbvgIvvfrm/36ic8Trj/RnxfzfSNu7m7s6NOKqfg/QuU9/Xht8B9MnjKNk6Xjuef4tt2OelDnZMZZceWJjWgAzgaVAdnDyI9baSad6TMOGSXb2nPP7YPOp7DuQ5XYEVz3z41q3I7hm6CVV3Y7gqpDvv/eQ71ZtdTuCax69/nLWL19y0gP6jm0xWWtnES7n4YqISK7RlR9ERMRTVEwiIuIpKiYREfEUFZOIiHjKKU9+MMak8fcJM3+dxGCDt621NrwuFyAiIiFxymKy1hYOZRARERE4w115xpgWxpibgrdLGmMqOhtLRETC1f8sJmPME8BDwMPBSZHAGCdDiYhI+DqTLaZuQBcgA8BamwpoN5+IiDjiTIop0wauW2QBjDHeuC66iIicl86kmD4xxrwDFDXG3Ap8D7zrbCwREQlX//NaedbaF40xlwD7gWrA49baaY4nExGRsHSmF3FdCuQnsDtvqXNxREQk3J3JWXm3AHOB7sBVwG/GmPD5EBcREQmpM9liGgg0sNbuAjDGlAB+AUY5GUxERMLTmZz8kAykHXU/DdjsTBwREQl3p7tW3v3BmynAHGPMBALHmLoS2LUnIiKS6063K++vP6JdF/z6ywTn4oiISLg73UVcnwxlEBERETiDkx+MMTHAICARyPfXdGvtxQ7mEhGRMHUmJz98BKwEKgJPAhuBeQ5mEhGRMHYmxVTCWvs+kGWt/dla2xdo4nAuEREJU2fyd0xZwX+3GGM6AqlAgnORREQknJ1JMT1tjCkCPAC8BkQD9zmaSkREwtaZXMT12+DNfUAbZ+OIiEi4O90f2L5G8DOYTsZae48jicKUP/uU3+qwMOTiKm5HcM3tny5xO4KrXu6a6HYE18xLTnc7gmsyMrNPOe90W0zzcz+KiIjI6Z3uD2xHhzKIiIgInNnp4iIiIiGjYhIREU9RMYmIiKecySfYVjPG/GCMWRa8X9cY86jz0UREJBydyRbTu8DDBK8AYa1dAvR0MpSIiISvMymmAtba4z8Y8IgTYURERM6kmHYaYyoT/GNbY8xVwBZHU4mISNg6k2vl9QdGAjWMMSnABuB6R1OJiEjYOpNr5a0H2hljCgIR1to052OJiEi4OpNPsH38uPsAWGuHOZRJRETC2Jnsyss46nY+oBOwwpk4IiIS7s5kV95LR983xrwIfO1YIhERCWtnc+WHAkCl3A4iIiICZ3aMaSl/fy5THiAG0PElERFxxJkcY+p01O0jwDZrrf7AVkREHHHaYjLGRAATrbW1Q5RHRETC3GmPMVlrs4HFxphyIcojIiJh7kx25ZUB/jDGzOWoU8ettV0cSyUiImHrTIrpScdTiIiIBJ1JMV1urX3o6AnGmOeBn52JJCIi4exM/o7pkpNM65DbQUREROA0W0zGmDuAO4FKxpglR80qDMx2OpiIiISn0+3K+xiYDDwLDD5qepq1drejqUREJGydspistfuAfUCv0MUREZFwdzbXyhMREXGMigmY+t0U6iZWJ7FGFYa/8JzbcRyVkryZqzq356LGdWnTtD7vvf1azrxRI9+gZaPatGlan6cff9jFlM5ISd5M906X0LJRHVo1rse7bwXG/uSjg2mRVJs2zS7gpuuuYt/eve4GzUV3NC/Huz3q8GLXmsdMv6xGDCO61eKlrjW5rmE8ADGFIhlzfX1e6FKDF7rU4NamZd2I7IjU5M1c06U9bRrXo23TBrz/9usALF+2hK7tL6Jd84bc1Ks7afv3u5w090x9dQjv3Nic/97d+YR5C74cxYiuNTm4fw8AW1cvYcyAboGve69g7a/TQh33GGdyuvhZMcbkA2YAUcH1fGatfcKp9Z0tv9/PgHv6M3HyNOITEmjRpBGdOnWhZq1abkdzhM/n44mnn6dOvQakp6VxWZsmtGrdjh07tvHdpG/4ftYCoqKi2Llju9tRc53P52Po0y9Qt35g7O0vakyrNm25qE1bhgx9Gp/Px1OPP8yrLz/PY8OedTturpi+djdTVuygf8sKOdMSSxciqVwRHpywgiPZluh8f78MbE07zKCvV7qQ1Fl5fD4ee+rvn/vLL25Ky9ZtGXjvHTw67FmaNm/FuDEf8PZrLzNwyFC34+aKWm2voH7Ha/luxOBjpqft2MKmRb9QOKZMzrQS5aty7UufEpHHR8bu7YwZ0I1KF7YhIo9jFXFaTm4xHQYuttbWA+oDlxljmji4vrMyb+5cKleuQsVKlYiMjOTqHj359psJbsdyTGzpMtSp1wCAQoULU7VaDbZuSeHDUSPpP2AgUVFRAJSMKeVmTEfEli5D3fpHjb16DbamptK67SX4fIFfwIaNGrMlNcXNmLlqxbZ00jP9x0xrXz2GCUu3cSQ78KEB+w+d/9dkPv7nvkrw5379mtU0adYSgFat2zL5m69cTJm7EhIbEVWo6AnTf37/OVr2eRCCn0YOkDcqf04JHcnKxGBOeFwoOVZMNiA9eDdv8Mue5iGuSE1NISHh710W8fEJpKScPy9Mp7P5z40sW7KYBg0vZP3aNcz9dTad2rXgyo7tWLRwvtvxHPXnpsDYL0i68JjpY8d8wMWXXOpSqtAoUySKGrGFeKZjdYZeVpXKJQrkzCtVKJLnO9dg6GVVqVGqoIspnbP5z438sWQRDRpeSPWaiUyd/C0A3074gtTUZJfTOWvdnB8pVCKWmIo1Tpi3ZdViPryrE2Pu6crFdzzh2tYSOHyMyRiTxxizCNgOTLPWzjnJMrcZY+YbY+bv2LnDyTgnZe2JXWmMu+8WQiEjPZ1bb+zJk8++SOHoaPxHjrBv7x6+mTaTR4c9y+03XXvS7835ICM9nVtu6MGw4Nj/MmL4s/h8Pq685loX0zkvwhgKReZhyMRV/Hd+Cve1rgjAngNZ3PnZMh76ZiWj5yVzz0UVyZ/3/DoMnZGeTr/evRj6r8D//YuvvcPo997m8jZNyUhPI2/eSLcjOibr8EHmfvoOTa+9+6Tzy1Svx42vf0uvFz9h3ufvciTzcIgT/s3Rnzprrd9aWx9IAC40xpzw8RnW2pHW2iRrbVJMyRgn45xUfHwCycmbc+6npCQTFxcX8hyhlJWVxa29e9Dt6p5c3vkKAMrEx9Oh8xUYY2jQsBERERHs3rXT3aAOyMrK4uYbetD9ml507NItZ/r4jz9k2neTeOPdD8/7Nya7D2Qy58+9AKzbeYBsC4WjfBzJtqQfDuz227DrINvSDlMmOp+LSXNXVlYWt/XuyRVX9aRD8Oe+SrXqfPzFRCb99Ctdr+xB+Yrn74dz79uymf3bkxkz4Arev7Ut6Tu38fF9V5Kx59gNguJlK5M3Kj+7Nq1xKWmIzsqz1u4FpgOXhWJ9/x9JjRqxdu0aNm7YQGZmJp+OH0fHTufvhdOttTxwdz+qVKtBv/4DcqZfenkXZs+YDsC6tavJzMyieImS7oR0iLWW++66jarVa3D7XQNypv/4/Xe8PuJFRo/7ggIFCpz6Cc4T8/7cR+3ShQEoEx2FL48h7fARCkf5cg47lCoUSZnCUWxLc+9dc26y1jLwnn5UrVaD2/rfmzP9r5N8srOzefWlZ7m+zy1uRXRcyQrV6PfhbG5+9wdufvcHCpWM5dpXPqdgsRj2bUsm2x841rh/ewp7UjYQHRvvWlYnz8qLAbKstXuNMfmBdsDzTq3vbPl8Pl759+t07ngpfr+f3n36Uisx0e1Yjpn32y98Pv4jataqzSUtGwEw+LFh9Ly+Dw/cdRsXN21A3shIRrz13nm35TD3t1/4bNxH1EysTdsWSQA8/PhTPDrofjIzD9PjisAlIBsmNeaFEW+4GTXX3NuqArVKF6ZwPh9vXV2bTxZt4cc1u7izeXle7FqTI9mWN2ZuBKBW6UJcU78MfmvJtvDur5vJOO7EiXPVvDm/8Pn4j6lRqzaXtgocV3zosWFsWLeW0e+/DUCHTlfQ47rebsbMVZNefIDkZXM5tH8v7/VtTZNed1H7kqtOumzq8gXM+/xdInx5McbQ5vbHyR9dLMSJ/2acOo5gjKkLjAbyENgy+8RaO+x0j2nYMMnOnnN+H3Q/ld3pmW5HcFWeiPOrBP8/7v5iqdsRXPVy1/P3jeD/8tLMDW5HcM3H91/FtrXLTvqL79gWk7V2CdDAqecXEZHz0/l1yo2IiJzzVEwiIuIpKiYREfEUFZOIiHiKiklERDxFxSQiIp6iYhIREU9RMYmIiKeomERExFNUTCIi4ikqJhER8RQVk4iIeIqKSUREPEXFJCIinqJiEhERT1ExiYiIp6iYRETEU1RMIiLiKSomERHxFBWTiIh4iopJREQ8RcUkIiKeomISERFPUTGJiIinqJhERMRTVEwiIuIpPrcDiIS7wa2ruB3BVVXbDXI7gmsqXtrR7Qiu2Z+Recp52mISERFPUTGJiIinqJhERMRTVEwiIuIpKiYREfEUFZOIiHiKiklERDxFxSQiIp6iYhIREU9RMYmIiKeomERExFNUTCIi4ikqJhER8RQVk4iIeIqKSUREPEXFJCIinqJiEhERT1ExiYiIp6iYRETEU1RMIiLiKSomERHxFBWTiIh4iopJREQ8RcUkIiKeomISERFPUTGJiIinqJhERMRTVEzA1O+mUDexOok1qjD8hefcjuOolOTNXNW5PRc1rkubpvV57+3XcuaNGvkGLRvVpk3T+jz9+MMupnRGSvJmune6hJaN6tCqcT3efSsw9icfHUyLpNq0aXYBN113Ffv27nU3qIPS9u9l0B030L1tEle2a8SShXMZ8a9H6d42iR6XNeOBfteRtn+v2zFzRUJsUaa8cxe/f/YwCz4ZTP9eFwFQp2oc0/8zgHnjH+KzV26lcMGonMc8eFM7ln31KIs/f4R2TWu4FT1XlC4SxX9uSeKbAc34+t5mXN+sHACX1o7l63ubsezpS0iMjz7mMbdeVJEpD7Rg4n3NaV61hBuxATDWWmdXYEweYD6QYq3tdLplGzZMsrPnzHc0z/H8fj91alVj4uRpxCck0KJJI0aPGUvNWrVCmmN3emZI1rNt6xa2b9tKnXoNSE9L47I2TRg15jN27NjGqy89x4fjJxAVFcXOHdspGVMqJJkA8kQYx9exbesWtm3dSt36gbG3v6gx//n4M7akpNDiojb4fD6eChbyY8OedTzPX1J2HwzZuh5/4HYaNGpKt569ycrM5NChAyxbtIBGzS7C5/Px6nOPA3DP4GEhy9T8yscced7SJaMpXTKaRSuTKVQgil/GPMg1D7zHe09ez+ARXzFr4Tpu7NKYCvElGPbWJGpUjGX0v3rT8saXKBNThElv9adOt6fJznbuNbLipR0de+6ShSOJKRzFitQ0CkTm4bO7mnD3mEVYC9nWMvSKWgyfvJo/UvYDULlUQYb3qEuPN3+jVHQ+3u/bkMtfnoVTw9/wn7s4uGX1SX/xQ7HFdC+wIgTrOSvz5s6lcuUqVKxUicjISK7u0ZNvv5ngdizHxJYuQ516DQAoVLgwVavVYOuWFD4cNZL+AwYSFRV49xjKUgqV2NJlqFv/qLFXr8HW1FRat70En88HQMNGjdmSmuJmTMekp+3n97mzuaLHjQDkjYykcHRRmrZqmzP+2g0asW1rqpsxc83WnftZtDIZgPQDh1m5YRtxpYpStXwpZi1cB8CPc1ZxxcX1AOjUug6fTl1IZpafTam7Wbd5B40Sy7uW/5/amZbJitQ0AA5k+lm/PYNS0VGs35HBxp0HTlj+4pqlmLxkK1l+S8qeg/y56wB1EoqEOjbgcDEZYxKAjsB7Tq7nn0hNTSEhoWzO/fj4BFJSzs8XpuNt/nMjy5YspkHDC1m/dg1zf51Np3YtuLJjOxYtDO2Wa6j9uSkw9guSLjxm+tgxH3DxJZe6lMpZKZs3Uqx4SYYOvJNrO7Zg2EN3cfBAxjHLfP3JGJpfdIlLCZ1Trkxx6tdIYN6yjSxft4VOF9UGoHu7+iTEFgUgPqYIyVv35jwmZds+4kq588Kc2+KK5qNmXGGWbN53ymVKRUexdd+hnPvb9h8itki+UMQ7gdNbTCOAQUD2qRYwxtxmjJlvjJm/Y+cOh+Oc6GS7Mo1xfreS2zLS07n1xp48+eyLFI6Oxn/kCPv27uGbaTN5dNiz3H7TtSf93pwPMtLTueWGHgwLjv0vI4Y/i8/n48prrnUxnXP8R46w8o/FXHXdzXw8cRb5CxTkP2+9kjP//deHk8fno8MV17iYMvcVzB/J2OF9GfjiF6RlHKbfsI/pd01LZo95kEIF8pGZ5Q8seJLf+/PhV6BAZB7+fV19np24iozD/lMud7KXPbdeA3xOPbExphOw3Vq7wBjT+lTLWWtHAiMhcIzJqTynEh+fQHLy5pz7KSnJxMXFhTpGSGVlZXFr7x50u7onl3e+AoAy8fF06HwFxhgaNGxEREQEu3ftpETJGHfD5rKsrCxuvqEH3a/pRccu3XKmj//4Q6Z9N4lPv/7uvH1jUqpMPKVKx1OnQRIA7Tp05T9vB4rpm88/ZuaP3/HWR1+fV+P3+SIYO7wv4yfPZ8JPSwBYvXE7nfu/BUCVcjF0aBE4npyyfS8JpYvmPDY+tghbdpx6C+Nc4IswjLi2Ht8u2sL3f2w/7bLb9h2m9FFbSLHR+di+/7DTEU/KyS2m5kAXY8xGYBxwsTFmjIPrOytJjRqxdu0aNm7YQGZmJp+OH0fHTl3cjuUYay0P3N2PKtVq0K//gJzpl17ehdkzpgOwbu1qMjOzKF6ipDshHWKt5b67bqNq9RrcfteAnOk/fv8dr494kdHjvqBAgQLuBXRYyZhYYsvEs3HdGgDm/vIzlapU55efv2f02yN45d1x5M9/fo3/7cd6sWrDNl79aHrOtJhihYDAnpHBN7fn3c9nAzDx52Vc3f4CIvPmoXxccaqUjWHeH5vciJ1rnuqeyPodGYye/b/H8dOK7XSoW5q8eQzxxfJTvmQBlia7U8yOn5UHENxietCLZ+UBTJk8iYEPDMDv99O7T18eenhIyDOE6qy8ub/OptvlF1OzVm1MROB9yeDHhtGydVseuOs2/li6mLyRkTz21HO0aNUmJJkgNGflzfl1Nl0va0PNxNpEBMf+8ONP8eig+8nMPEyx4sUBaJjUmBdGvOF4nr+E8qy8VcuX8NTgu8nKzCK+XAWGDn+DG7q2ISszkyJFA+Ov0yCJR54ZEbJMTp2V16x+JX54/16WrkklOztwNOGJNyZSpVwM/a5uAcCEn5bw2Gvf5DxmUN9L6N21CUeO+Bn40pdM/cXZ87acPCvvgvJFGdPvQlZtScvZJTdi6lry+iIY0rkGxQtGsv9QFitT07jtg4UA9GtdkW4N4/FnW56buIqZq3c6lu90Z+WpmDwiVMXkVaEoJq8KZTF5kVPFdC5wspi87nTF5NgxpqNZa6cD00OxLhERObfpyg8iIuIpKiYREfEUFZOIiHiKiklERDxFxSQiIp6iYhIREU9RMYmIiKeomERExFNUTCIi4ikqJhER8RQVk4iIeIqKSUREPEXFJCIinqJiEhERT1ExiYiIp6iYRETEU1RMIiLiKSomERHxFBWTiIh4iopJREQ8RcUkIiKeomISERFPUTGJiIinqJhERMRTVEwiIuIpPrcDSMDny1LcjuCqLxZscTuCa6IL5HU7gqsa9LjS7Qiu+X3sJ25HcM3hfXtPOU9bTCIi4ikqJhER8RQVk4iIeIqKSUREPEXFJCIinqJiEhERT1ExiYiIp6iYRETEU1RMIiLiKSomERHxFBWTiIh4iopJREQ8RcUkIiKeomISERFPUTGJiIinqJhERMRTVEwiIuIpKiYREfEUFZOIiHiKiklERDxFxSQiIp6iYhIREU9RMYmIiKeomERExFNUTCIi4ikqJhER8RQVk4iIeIrP7QBeMPW7KTx4/734/X769L2FgYMGux0pV3307CD++OUnChcrwcMfTgHg958mMXnUv9m2aS0PjPyScjXqAuA/ksXY5x9m8+plZPv9NLq0G+1vuNPN+P/YoHaVaVKxOHsPZNH3o0UAVC5ZgPsvrkykLwJ/tmXET+tZuS2d2MJRjL6xPpv3HAJg+dY0XvlxvYvp/5m7W1UgqVxR9h3M4p7P/wBg4MWViSuaD4CCkXnIyPRz3xd/UC8+mhsbJeDLYzjit3wwdzNLU9PcjP+PPXJZNZpXLs6eA1lc/58FAFSJKcig9lXJH5mHLfsOMfTblRzI9FOzdGEeurQqAMbA+7M3MWPNLjfj/yMJsUV576kbiS0RTba1jPp8Nm+MnU6davG8NqQnBfNHsSl1FzcNGU1axiGSEsvz+mO9gMD4n3l7El//tMSV7I4WkzFmI5AG+IEj1tokJ9d3Nvx+PwPu6c/EydOIT0igRZNGdOrUhZq1arkdLdc07nAVrbrfyJhnHsyZVqZiNW5+5i3GDx9yzLK//zSJI5mZPDx6CpmHDvKvG9rTsF0XSpRJCHXsXDNl+Q6+XLyVh9tXzZnWr0UFRs/ZzNxNe2lcoSj9WpTnvuALd+rew9z68WK34uaqH1bvZOIf2xnQumLOtOE/rsu5fVPjshzI9AOw/9ARnpm6ht0HsihXLD9DO1Sj7zn+fZi0bBuf/Z7K45dXz5n28GXVeG36ehZt3kfHOrFcd2EC787axPqdGdz84UL8FkoUjOTDPhcwe+0u/NbFAfwDR/zZDH75CxatTKZQgSh++fghfpizkrcev5bBr3zJrAVrubFrE+7r3ZZhb07kj3WpNL/uBfz+bEqXjGbO+IeZOGMZfn92yLOHYldeG2ttfS+WEsC8uXOpXLkKFStVIjIykqt79OTbbya4HStXVal/IQWiix4zrXSFKsSWq3TCssYYDh86gP/IEbIOHyKPLy/5ChYKUVJnLEndz/5DR46baikYmQeAgpE+dmVkhj5YCCzfmk764ePH/rcWlYozY11gq2DDrgPsPpAFwJ97DpI3TwS+CBOSnE5ZlLyP/QezjplWrnh+Fm3eB8C8jXtpXa0kAIePZOeUUKQvgnO0j3Js3bmfRSuTAUg/cJiVG7YSF1OUquVLMWvBWgB+/G0lV7StD8DBQ1k5JRQVmRdr3fsOhP2uvNTUFBISyubcj49PYO7cOS4mclf91h1YOvN7Hr2iCVmHD9Lt7kcpeFypnQ9e/3kjL3Srxe0tK2AM3P3Jspx5pYtEMbJXXQ5k+nn/1z/P+d1Zp1KrdCH2Hsxiy/7DJ8xrVrEYG3ZlcCT7XH95PtH6nRm0rFKCmWt3cXH1kpSKjsqZV6tMYR7pUI3S0fkYNnHlObu1dLxyZYpTv3oC85ZtZPm6LXRqXYdvpy+l+yUXkBBbLGe5RrXL8/bQ6ylXpjg3Pzrala0lcH6LyQJTjTELjDG3nWwBY8xtxpj5xpj5O3bucDjOiU72rsCYc/td4j+xafliTJ4Inv7qV5745Gd+GvceO1P/dDtWrutatzRvzthAj1ELeHPGRga2qwzA7gOZ9By1gNvGLuHNmRt59LJqFAhuWZ1vWlUukbO1dLSyxfJx44UJvDlzkwupnPevyau5skEco25sQIHIPBw5qn2Wb0nj+lELuPnDhdzYpCyRec7914KC+SMZ++ItDHzxc9IyDtFv6Ef0u6YVsz8aRKECUWRm+XOWnbdsEw2veoYW17/AwL7tiYp0Z9vF6WJqbq29AOgA9DfGtDp+AWvtSGttkrU2KaZkjMNxThQfn0By8uac+ykpycTFxYU8h1fM//5ral54EXl8eSlcrCQV6zTkz5VL3Y6V69rXjGHG2t0ATF+zixqxgd2VWX6bs9tv9fYMUvcdIiF4osD5JMJA0wrFmLV+9zHTSxTMy8OXVGXE9A1sTTtxS+p8sGn3QQZ8upS+H/7OtBU7SNl78KTLHMzKplJMQRcS5h6fL4KxL97K+MnzmfBj4Hjh6o3b6HznGzS/7gU+mbKADcknbhCs2rCNjIOZJFZx57XQ0WKy1qYG/90OfAlc6OT6zkZSo0asXbuGjRs2kJmZyafjx9GxUxe3Y7mmWGwcaxb+grWWwwcPsPGPRSc9FnWu25WRSb34aAAuKFuElL2Bs/CK5Pfx12GVMtFRxBfNx5Z9598LdL34aJL3HWRXxt/HXwpG5uGxS6vx37nJrNyW7mI6ZxUrkBcAA/RpWo4vF20BoEyRfPy1gVQ6OopyxfOzZd8hl1LmjrefuI5VG7by6pgfc6bFFAu8CTPGMPjWS3n3s1kAlI8rQZ48gUooV6YY1SrEsinVnbMSHdtOM8YUBCKstWnB2+2BYU6t72z5fD5e+ffrdO54KX6/n959+lIrMdHtWLnqg6H3sPb3OaTv28Nj3Ztxed97KRBdlM9GPEn63t28M+hm4qvU4s6XR9Oq2w189Owgnr3xMqy1NLn8KuKr1HR7CP/Io5dVpX5CEYrk8/FJ34Z8MGczL/6wjrtbVSRPhCHTn81LwTPV6sVHc1OTcvizLX5reeXH9aSd5uQBr3ugTSVqxxUmOp+P93vVY+zCFL5ftZOWlUswc92xW0uXJ5aiTHQU11wQxzUXBN4pD520in0nnDhy7niycw0alC1C0fx5+eqOxrw3axMFIiPo3iAwvp9X72Ti0m1A4P/++isTOeK3WCwvTV3LvoPn7tib1a/EdZ0as3R1Cr+NC/wJzBOvf02VsqXo1yOw82rCj4v4cMJvgeUbVOLBm9qTdcRPdrbl3n+NZ9feDFeyG6fOvDDGVCKwlQSBAvzYWvvM6R7TsGGSnT1nviN5vO7d3za4HcFVXyzY4nYE10QH38GHqx17TtyVFi5+H/uJ2xFcc3jVJ2Qf2H7Sg3iObTFZa9cD9Zx6fhEROT/pkkQiIuIpKiYREfEUFZOIiHiKiklERDxFxSQiIp6iYhIREU9RMYmIiKeomERExFNUTCIi4ikqJhER8RQVk4iIeIqKSUREPEXFJCIinqJiEhERT1ExiYiIp6iYRETEU1RMIiLiKSomERHxFBWTiIh4iopJREQ8RcUkIiKeomISERFPUTGJiIinqJhERMRTVEwiIuIpKiYREfEUY611O0MOY8wOYJNLqy8J7HRp3V4QzuMP57FDeI9fY3dPeWttzMlmeKqY3GSMmW+tTXI7h1vCefzhPHYI7/Fr7N4cu3bliYiIp6iYRETEU1RMfxvpdgCXhfP4w3nsEN7j19g9SMeYRETEU7TFJCIinqJiEhERT1ExAcaYy4wxq4wxa40xg93OE0rGmFHGmO3GmGVuZwk1Y0xZY8xPxpgVxpg/jDH3up0pVIwx+Ywxc40xi4Njf9LtTKFmjMljjPndGPOt21lCzRiz0Riz1BizyBgz3+08xwv7Y0zGmDzAauASIBmYB/Sy1i53NViIGGNaAenAh9ba2m7nCSVjTBmgjLV2oTGmMLAAuCIc/u+NMQYoaK1NN8bkBWYB91prf3M5WsgYY+4HkoBoa20nt/OEkjFmI5BkrfXkHxdriwkuBNZaa9dbazOBcUBXlzOFjLV2BrDb7RxusNZusdYuDN5OA1YA8e6mCg0bkB68mzf4FTbvUo0xCUBH4D23s8iJVEyBF6LNR91PJkxenORvxpgKQANgjstRQia4K2sRsB2YZq0Nm7EDI4BBQLbLOdxiganGmAXGmNvcDnM8FROYk0wLm3eOAsaYQsDnwABr7X6384SKtdZvra0PJAAXGmPCYleuMaYTsN1au8DtLC5qbq29AOgA9A/u0vcMFVNgC6nsUfcTgFSXskiIBY+vfA58ZK39wu08brDW7gWmA5e5myRkmgNdgsdZxgEXG2PGuBsptKy1qcF/twNfEjik4RkqpsDJDlWNMRWNMZFAT+BrlzNJCARPAHgfWGGtfdntPKFkjIkxxhQN3s4PtANWuhoqRKy1D1trE6y1FQj8vv9orb3e5VghY4wpGDzZB2NMQaA94KmzcsO+mKy1R4C7gO8IHPz+xFr7h7upQscYMxb4FahujEk2xtzsdqYQag7cQOAd86Lg1+VuhwqRMsBPxpglBN6cTbPWht1p02EqFphljFkMzAUmWmunuJzpGGF/uriIiHhL2G8xiYiIt6iYRETEU1RMIiLiKSomERHxFBWTiIh4iopJ5CwZY1r/dWVqY0yX012Z3hhT1Bhz51msY6gx5sEznX7cMh8YY676f6yrQjheZV68R8UkcpzgFef/X6y1X1trnzvNIkWB/3cxiYQjFZOEjeAWwUpjzGhjzBJjzGfGmALBeRuNMY8bY2YBVxtj2htjfjXGLDTGfBq8nt5fn921Mrhc96Oeu48x5vXg7VhjzJfBzzpabIxpBjwHVA7+Ee/w4HIDjTHzglmePOq5hgQ/H+x7oPoZjOvW4PMsNsZ8/teYgtoZY2YaY1YHrxH318Vbhx+17n7/9HsrkptUTBJuqgMjrbV1gf0cuxVzyFrbAvgeeBRoF7zQ5XzgfmNMPuBdoDPQEih9inW8Cvxsra0HXAD8AQwG1llr61trBxpj2gNVCVyjrD7Q0BjTyhjTkMBlchoQKL5GZzCmL6y1jYLrWwEcffWOCsBFBD7i4e3gGG4G9llrGwWf/1ZjTMUzWI9ISPjcDiASYputtbODt8cA9wAvBu+PD/7bBKgFzA5cTo9IApdtqgFssNauAQhe+PNkHxlwMXAjBK7gDewzxhQ7bpn2wa/fg/cLESiqwsCX1toDwXWcyXUbaxtjniawu7AQgctr/eUTa202sMYYsz44hvZA3aOOPxUJrnv1GaxLxHEqJgk3x1+D6+j7GcF/DYFrx/U6ekFjTP2TPP5sGeBZa+07x61jwFms4wMCn7y72BjTB2h91LyTjdcAd1trjy6wvz6TSsR12pUn4aacMaZp8HYvAh8pfrzfgObGmCoAxpgCxphqBK6+XdEYU/mox5/MD8AdwcfmMcZEA2kEtob+8h3Q96hjV/HGmFLADKCbMSZ/8ArQnc9gTIWBLcGP8LjuuHlXG2MigpkrAauC674juDzGmGrBq0yLeIKKScLNCqB38KraxYG3jl/AWrsD6AOMDS73G1DDWnuIwK67icGTHzadYh33Am2MMUuBBUCitXYXgV2Dy4wxw621U4GPgV+Dy30GFA5+1Pt4YBGBz4maeQZjeozAJ+9O48SPrlgF/AxMBm4PjuE9YDmwMHh6+Dto74l4iK4uLmEjuKvqW2ttWHxSq8i5SltMIiLiKdpiEhERT9EWk4iIeIqKSUREPEXFJCIinqJiEhERT1ExiYiIp/wfLrVSYy4hq34AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import tqdm.auto for progress bar tracking\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#1. Make predictions with trained model\n",
    "y_preds = []\n",
    "model_multiclass.eval()\n",
    "with torch.inference_mode():\n",
    "  for X, y in tqdm(test_loader, desc = \"Making predictions...\"):\n",
    "    # Send the data and targets to target device\n",
    "    # DO the forward pass\n",
    "    y_logits = model_multiclass(X)\n",
    "    #Turn prediction from logits -> prediction porbabilities -> prediction labels\n",
    "    y_pred = torch.softmax(y_logits.squeeze(), dim =0).argmax(dim=1)+1\n",
    "    # Put predictions on CPU for evaluation\n",
    "    y_preds.append(y_pred)\n",
    "\n",
    "  #COncatenate list of predictions into a tensor\n",
    "  #print(y_preds)\n",
    "y_pred_tensor = torch.cat(y_preds)\n",
    "y_pred_tensor\n",
    "\n",
    "try:\n",
    "  import torchmetrics, mlxtend\n",
    "  print(f\"mlxtend version: {mlxtend.__version__}\")\n",
    "  assert int(mlxtend.__version__.split(\".\")[1]) >=19, \"mlxtend version should be 0.19.0 or higher\"\n",
    "except:\n",
    "  !pip install -q torchmetrics -U mlxtend\n",
    "  import torchmetrics, mlxtend\n",
    "  print(f\" mlxtend version: {mlxtend.__version__}\")\n",
    "\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "# 2. Setup confusion instance and compare predictions to targets\n",
    "confmat = ConfusionMatrix(task = \"multiclass\",\n",
    "                          num_classes=6)\n",
    "\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "print(y_test_tensor)\n",
    "print(y_pred_tensor)\n",
    "confmat_tensor = confmat(preds = y_pred_tensor,\n",
    "                         target = y_test_tensor)\n",
    "\n",
    "#3. Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat = confmat_tensor.numpy(), #matplotlib likes working with numpy\n",
    "    figsize=(10,7)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f261a4a",
   "metadata": {},
   "source": [
    "#### Edit confusion matrix to get rid of class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30a33c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
