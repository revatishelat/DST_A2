{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc2da04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.9/site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (1.25.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install nltk\n",
    "!pip install scikit-learn\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f12b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6076a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data_proc = []\n",
    "    for doc in data['medical_abstract']:\n",
    "        #lowercases document\n",
    "        doc = doc.lower()\n",
    "        #removes any non-letter characters\n",
    "        doc = re.sub(r'\\b[^a-zA-Z]+\\b', ' ', doc)\n",
    "        #tokenize\n",
    "        toks = nltk.word_tokenize(doc)\n",
    "        #remove tokens of lenth <= 1 (can be varied)\n",
    "        toks = [tok for tok in toks if len(tok) > 1]\n",
    "        #remove stopwords\n",
    "        toks = [tok for tok in toks if tok not in en_stop]\n",
    "        #lemmatize\n",
    "        toks = [WordNetLemmatizer().lemmatize(tok) for tok in toks]\n",
    "        data_proc.append(toks)\n",
    "    return data_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c457126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv('medical_tc_labels.csv')\n",
    "df_train = pd.read_csv('medical_tc_train.csv')\n",
    "df_test = pd.read_csv('medical_tc_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6006633",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train_proc = preprocess(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aed2da39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11550"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_train_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882e811c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tissue change around loose prosthesis canine model investigate effect antiinflammatory agent aseptically loosened prosthesis provided mean investigating vivo vitro activity cell associated loosening process seven dog cell isolated maintained culture sufficient period time biologic activity could studied well effect different agent added cell vivo vitro biologic response determined interleukin prostaglandin e2 activity paralleled roentgenographic appearance loosening technetium image observation made time revision surgery correlation clinical roentgenographic histologic biochemical loosening indicates canine model suitable investigating mechanism prosthetic failure canine model permit study possible nonsurgical therapeutic intervention ultimate hope stopping slowing loosening process\n"
     ]
    }
   ],
   "source": [
    "#CountVectorizer wont accept tokenized text\n",
    "docs_train_clean = []\n",
    "for doc in docs_train_proc:\n",
    "    doc_clean = ' '.join(doc)\n",
    "    docs_train_clean.append(doc_clean)\n",
    "print(docs_train_clean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e59e4cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11550, 30580)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer()\n",
    "\n",
    "bow_matrix = count.fit_transform(docs_train_clean).toarray()\n",
    "bow_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efe75d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ord = df_train['condition_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab88e16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11550,)\n",
      "(11550, 30580)\n"
     ]
    }
   ],
   "source": [
    "print(labels_ord.shape)\n",
    "print(bow_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7218b1bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bow_matrix_lab \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabels_ord\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbow_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/numpy/core/shape_base.py:357\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arrs \u001b[38;5;129;01mand\u001b[39;00m arrs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "bow_matrix_lab = np.hstack([labels_ord,bow_matrix.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0745ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['condition_label', 'medical_abstract'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_proc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7586242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "v = np.array([1,0,1])\n",
    "M = np.array([[1,2,1],[1,2,3]])\n",
    "print(v.shape)\n",
    "print(M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74a63afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [1, 2, 1],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([v,M])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
